{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re, pickle, os, string\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import nltk\n",
    "import string\n",
    "import spacy\n",
    "from nltk.corpus import stopwords\n",
    "from spacy.util import compile_prefix_regex, compile_infix_regex, compile_suffix_regex\n",
    "from spacy.tokenizer import Tokenizer\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style('whitegrid')\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        label                                              Tweet\n",
      "0        8746     @handle Let's try and catch up live next week!\n",
      "1        8746  Going to watch Grey's on the big screen - Thur...\n",
      "2        8746  @handle My pleasure Patrick....hope you are well!\n",
      "3        8746  @handle Hi there! Been traveling a lot and lot...\n",
      "4        8746  RT @handle Looking to Drink Clean & Go Green? ...\n",
      "5        8746  RT @handle: Ft. Hood officials confirm the 2 o...\n",
      "6        8746  RT @handle: Mickey Mouse is Getting a Make Ove...\n",
      "7        8746           @handle How did u get the invite Justin?\n",
      "8        8746  @handle I think I am still a good friend of he...\n",
      "9        8746  @handle I remember! I am fine - how are u? Wha...\n",
      "10       8746     @handle That's great - good for the coach!!!!!\n",
      "11       8746  @handle I don't want to picture u sitting on i...\n",
      "12       8746  @handle D- Thanks for the RTs....are you going...\n",
      "13       8746           @handle Grrr....you must be going crazy!\n",
      "14       8746  @handle Hi there - just catching up from my tr...\n",
      "15       8746  RT @handle: If you're looking for some great l...\n",
      "16       8746  RT @handle: Retailers who aren’t engaging cust...\n",
      "17       8746  RT @handle: Director of Global Brand Marketing...\n",
      "18       8746  Still in car....want to jump out....45 minutes...\n",
      "19       8746  RT @handle: \"Only surround yourself with peopl...\n",
      "20       8746  @handle wish I could but 24/7 w stu's family t...\n",
      "21       8746  RT @handle: Help us help MusiCares! Vote for C...\n",
      "22       8746                     @handle yum!!!! Save me some!!\n",
      "23       8746  RT @handle: Gratitude is the sign of noble sou...\n",
      "24       8746           @handle I don't think I know what it is!\n",
      "25       8746  RT @handle: @handle Just found you via @handle...\n",
      "26       8746  RT @handle: RT @handle: Travelling for the Hol...\n",
      "27       8746       Just entering ohio - special hi to @handle!!\n",
      "28       8746  @handle well we agree on one food thing friend...\n",
      "29       8746                                @handle only 1!!!!!\n",
      "...       ...                                                ...\n",
      "328902   1319                                            @handle\n",
      "328903   1319  @handle Please add me to the #awsms09 afterpar...\n",
      "328904   1319  @handle great party last night...met some tale...\n",
      "328905   1319  Alta Phoenix Lofts #1 Phoenix!!!!! Congrats to...\n",
      "328906   9235                You manage things; you lead people.\n",
      "328907   9235  Not to know is bad; not to wish to know is worse.\n",
      "328908   9235  That there should one man die ignorant who had...\n",
      "328909   9235                       Will is character in action.\n",
      "328910   9235     What the mind dwells upon, the body acts upon.\n",
      "328911   9235      Success as I see it, is a result, not a goal.\n",
      "328912   9235  All generalizations are false, including this ...\n",
      "328913   9235  It is the province of knowledge to speak and i...\n",
      "328914   9235  A leader, once convinced that a particular cou...\n",
      "328915   9235  You can not make excuses and money at the same...\n",
      "328916   4357  Henry Brothers Electronics, Inc. to Participat...\n",
      "328917   4357  TechInsights' ESC UK Event Showcases Leading C...\n",
      "328918   4357  DEMOfall 09 Announces Lineup of Emerging Techn...\n",
      "328919   4357  AFP Hosts Symposium on Essentials for Doing Bu...\n",
      "328920   4357  AlertEnterprise Wins ASIS Accolades 2009 Secur...\n",
      "328921   4357  Andrews International Introduces New Methodolo...\n",
      "328922   4357  Innovation Strong Despite Recession: Human Res...\n",
      "328923   4357  VideoIQ and Milestone Systems Partner to Deliv...\n",
      "328924   4357  Phoenix Technologies to Showcase Cutting Edge ...\n",
      "328925   4357  AnyDATA's APT-210 Tracking Device Measures Att...\n",
      "328926   4357  Samplify Systems Announces Distribution Agreem...\n",
      "328927   4357  Steelbox Demonstrates Open Video Framework wit...\n",
      "328928   4357  Small Businesses Rely on Sage to Help Them Rid...\n",
      "328929   4357  TimeSight Systems™ Announces Next-Generation P...\n",
      "328930   4357  Diebold Makes Its Leading Monitoring Solutions...\n",
      "328931   4357  GVI Security Solutions to Introduce AutoIP™ VM...\n",
      "\n",
      "[328932 rows x 2 columns]\n",
      "                                                   Tweet\n",
      "0      Some people say that rappers don’t have feelin...\n",
      "1      Do you know how to tweet on a Blackberry 8830?...\n",
      "2            \"Yoga is the cessation of mind.\" -Patanjali\n",
      "3      @handle Well, with my millions of dollars, a f...\n",
      "4      Cambria hotels free guide http://hotels.izigot...\n",
      "5      May the force of Jesus be with you http://ff.i...\n",
      "6                             YEAH! It's finally Monday!\n",
      "7      Martin Laird won in Las Vegas last week with a...\n",
      "8      Joe's Crab Shack Fundraiser benefitting the Sa...\n",
      "9      i hate my self-portrait painting, I don't know...\n",
      "10     FREE system to generate leads! http://bit.ly/1...\n",
      "11     Life is tough. But Jesus softens it. Work with...\n",
      "12     @handle What is really tragic is the amount of...\n",
      "13     @handle Christine Lahti, she is going to be ar...\n",
      "14     RT @handle: @handle Does Twitter special inclu...\n",
      "15     hello my lovely's..let's get it!! @handle @han...\n",
      "16     New Blog Post! @handle's top fashion week pick...\n",
      "17     Control your diet by drinking plenty of water,...\n",
      "18     rt @handle 20 breathtaking realistic CG portra...\n",
      "19     @handle only plays german speed techno @handle...\n",
      "20     @handle yes please!!! what's your week looking...\n",
      "21                                      Hey chic @handle\n",
      "22     CleanTech's Ten Clean Technology Predictions f...\n",
      "23     5 of the Best Free and Open Source CD/DVD Writ...\n",
      "24     Check out the November edition of Factory Dire...\n",
      "25     lmfao! RT @handle @handle yea but without the ...\n",
      "26     RT @handle \"Your future is spotless, The only ...\n",
      "27     #Ad Really good site for community building #t...\n",
      "28                     Love getting my glow on in miami!\n",
      "29              Hardesty's spin move=badass. Give him 6!\n",
      "...                                                  ...\n",
      "35407  RT @handle Confrontation leads to solutions.: ...\n",
      "35408  \"no talking rule\" in effect for the Raider gam...\n",
      "35409                                   @handle Will do!\n",
      "35410  2034 Bobwhite Lane, Santa Cruz, CA 95065 - pre...\n",
      "35411  @handle I think there's a shot. Figgins. Polan...\n",
      "35412  Stand Up To Cancer!! Andrew McMahon of @handle...\n",
      "35413                @handle You are very welcome, Mark.\n",
      "35414  Vegas stereotype: 6 Asian girls stumbling by d...\n",
      "35415                   Red, red wine. Stay close to me.\n",
      "35416  Should health care workers be required to get ...\n",
      "35417  just joined a video chat with 2 other people a...\n",
      "35418  Celebrated 30 days sobriety n 10 pounds lost w...\n",
      "35419  @handle I never read the book! They have the c...\n",
      "35420  I just got an email from an affiliate of Sterl...\n",
      "35421     Meeting hubby for lunch-unexpected surprise :)\n",
      "35422                                       @handle LMAO\n",
      "35423  @handle yess OOO! I'm back in the lab cooking ...\n",
      "35424  Spent the afternoon taking care of a sick sist...\n",
      "35425                 searching for social media experts\n",
      "35426  The results are in ... see who won the Battle ...\n",
      "35427  RT @handle: @handle It always amazes me when s...\n",
      "35428  How To Get A Google Wave Account http://bit.ly...\n",
      "35429  Think spring: It's time to plan your garden ht...\n",
      "35430          Working in the villages tonight. Text me!\n",
      "35431  omg, Jimmy Choo is coming out with a line for ...\n",
      "35432  NCAA Football Odds - West Virginia at Cincinna...\n",
      "35433              @handle My favorite color!! Congrats!\n",
      "35434  It's not a simple matter to let others know wh...\n",
      "35435  Funny. The \"Smoke N Drank\" track off of In a M...\n",
      "35436                                   @handle Sup hun?\n",
      "\n",
      "[35437 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "train_data = None\n",
    "test_data = None\n",
    "\n",
    "def load_data():\n",
    "    global train_data, test_data\n",
    "    train_data = pd.read_csv('train_tweets.txt', delimiter=\"\\t\", header = None, quoting=csv.QUOTE_NONE)\n",
    "    test_data = pd.read_csv('test_tweets_unlabeled.txt', delimiter=\"\\t\", header = None, quoting=csv.QUOTE_NONE)\n",
    "    \n",
    "load_data()\n",
    "train_data.columns = ['label','Tweet']\n",
    "test_data.columns = ['Tweet']\n",
    "\n",
    "print(train_data)\n",
    "print(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9297\n"
     ]
    }
   ],
   "source": [
    "### computing the number of label\n",
    "numLabel = train_data['label'].unique()\n",
    "print(len(numLabel))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### bag-of-words feature matrix\n",
    "# from sklearn.feature_extraction.text import CountVectorizer\n",
    "       \n",
    "# bow_vectorizer = CountVectorizer(max_features = 30)\n",
    "\n",
    "# allData = train_data['Tweet'].values.tolist() + test_data['Tweet'].values.tolist()\n",
    "# #print(\"allData=\"+str(allData))\n",
    "\n",
    "# bowAllData = bow_vectorizer.fit_transform(allData) \n",
    "# #bowTrain = bow_vectorizer.fit_transform(train_data['Tweet']) \n",
    "# #bowTest = bow_vectorizer.fit_transform(test_data['Tweet']) \n",
    "\n",
    "# #bowArray = bowTrain.toarray()\n",
    "# #get_feature_names()可获取词袋中所有文本的关键字\n",
    "# #toarray()可看到词频矩阵的结果\n",
    "        \n",
    "# train_tagged = bow_vectorizer.get_feature_names()\n",
    "# print (bow_vectorizer.get_feature_names())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer(max_features = 50000)\n",
    "allData = train_data['Tweet'].values.tolist() + test_data['Tweet'].values.tolist()\n",
    "bowAllData = vectorizer.fit_transform(allData) \n",
    "train_tagged = vectorizer.get_feature_names()\n",
    "# print (bow_vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "from sklearn import linear_model\n",
    "reg = linear_model.LinearRegression()\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import make_classification\n",
    "# train_bow = bow[:328195, :]\n",
    "# xtrain_bow, xvalid_bow, ytrain, yvalid = train_test_split(train_bow, train_data['label'], test_size=0.2)\n",
    "# lsvc=LinearSVC()\n",
    "# lsvc.fit(xtrain_bow, ytrain)\n",
    "# prediction = lsvc.predict_proba(xvalid_bow)\n",
    "# predictLabel = lsvc.predict(xvalid_bow)\n",
    "# print(lsvc.predict(xvalid_bow))\n",
    "lentrain = len(train_data)\n",
    "\n",
    "# Separate back into training and test sets.\n",
    "train = bowAllData[:lentrain]  \n",
    "test = bowAllData[lentrain:]\n",
    "# print (train)\n",
    "# print (test)\n",
    "#trainLabel = str(train_data['label'].unique())\n",
    "#print(\"label=\"+str(train_data['label'].unique()))\n",
    "#print(lreg.classes_) \n",
    "# ==========================\n",
    "lsvc=LinearSVC()\n",
    "reg.fit(train, train_data['label']) # training the model\n",
    " \n",
    "# trainPrediction = lsvc.predict_proba(test) # predicting on the validation set\n",
    "\n",
    "prediction = reg.predict(test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 47838)\t0.3455188467291028\n",
      "  (0, 30437)\t0.35786558425796877\n",
      "  (0, 26411)\t0.35432756484743455\n",
      "  (0, 46247)\t0.26468242805316344\n",
      "  (0, 9025)\t0.4734333854711045\n",
      "  (0, 4094)\t0.18616893183949454\n",
      "  (0, 45144)\t0.3969651830207234\n",
      "  (0, 26013)\t0.35337990028941973\n",
      "  (0, 20611)\t0.1252492998293246\n",
      "  (1, 44033)\t0.40796730525536345\n",
      "  (1, 38583)\t0.46622269051638593\n",
      "  (1, 6559)\t0.3274541708275878\n",
      "  (1, 43698)\t0.12575876517852225\n",
      "  (1, 31597)\t0.1795391211956382\n",
      "  (1, 19986)\t0.506824198898586\n",
      "  (1, 47609)\t0.3236480565418275\n",
      "  (1, 44325)\t0.13668021176436548\n",
      "  (1, 19538)\t0.28394184309217335\n",
      "  (2, 47919)\t0.3513089581615435\n",
      "  (2, 4587)\t0.25546724741925203\n",
      "  (2, 49541)\t0.19218804734601225\n",
      "  (2, 21807)\t0.368168772774643\n",
      "  (2, 32699)\t0.516419438921033\n",
      "  (2, 33764)\t0.5543730160522097\n",
      "  (2, 29803)\t0.2217525426643054\n",
      "  :\t:\n",
      "  (328930, 29175)\t0.35806466691579575\n",
      "  (328930, 40704)\t0.31820328232070194\n",
      "  (328930, 25805)\t0.3133330017403701\n",
      "  (328930, 12788)\t0.375951744930711\n",
      "  (328930, 5236)\t0.24900597983321177\n",
      "  (328930, 27298)\t0.231624427156579\n",
      "  (328930, 23702)\t0.19437602068598855\n",
      "  (328930, 27010)\t0.0918916523015251\n",
      "  (328930, 6727)\t0.0941029420000068\n",
      "  (328930, 22037)\t0.07330670703717689\n",
      "  (328930, 44325)\t0.08725992248231397\n",
      "  (328931, 44739)\t0.36574041947723535\n",
      "  (328931, 38111)\t0.34039259219630696\n",
      "  (328931, 15330)\t0.35493843564652966\n",
      "  (328931, 23413)\t0.34185705937176386\n",
      "  (328931, 49862)\t0.3542280270052108\n",
      "  (328931, 40704)\t0.3112477972712632\n",
      "  (328931, 38758)\t0.2818040519608275\n",
      "  (328931, 25805)\t0.3064839743098347\n",
      "  (328931, 22932)\t0.26865526683008767\n",
      "  (328931, 27010)\t0.08988302747185628\n",
      "  (328931, 6727)\t0.09204598142620112\n",
      "  (328931, 22037)\t0.0717043234882015\n",
      "  (328931, 44325)\t0.08535254088079669\n",
      "  (328931, 4094)\t0.1032812180553466\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import make_classification\n",
    "# train_bow = bow[:328195, :]\n",
    "# xtrain_bow, xvalid_bow, ytrain, yvalid = train_test_split(train_bow, train_data['label'], test_size=0.2)\n",
    "# lsvc=LinearSVC()\n",
    "# lsvc.fit(xtrain_bow, ytrain)\n",
    "# prediction = lsvc.predict_proba(xvalid_bow)\n",
    "# predictLabel = lsvc.predict(xvalid_bow)\n",
    "# print(lsvc.predict(xvalid_bow))\n",
    "lentrain = len(train_data)\n",
    "\n",
    "# Separate back into training and test sets.\n",
    "train = bowAllData[:lentrain]  \n",
    "test = bowAllData[lentrain:]\n",
    "print (train)\n",
    "# print (train)\n",
    "# print (test)\n",
    "#trainLabel = str(train_data['label'].unique())\n",
    "#print(\"label=\"+str(train_data['label'].unique()))\n",
    "#print(lreg.classes_) \n",
    "# ==========================\n",
    "lsvc=LinearSVC()\n",
    "lsvc.fit(train, train_data['label']) # training the model\n",
    " \n",
    "# trainPrediction = lsvc.predict_proba(test) # predicting on the validation set\n",
    "\n",
    "prediction = lsvc.predict(test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-633f4171cdba>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'train' is not defined"
     ]
    }
   ],
   "source": [
    "print (train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def save_pickle(data, filepath):\n",
    "    save_documents = open(filepath, 'wb')\n",
    "    pickle.dump(data, save_documents)\n",
    "    save_documents.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "save_pickle(lsvc, os.path.join('tfidf5WLSVC.p'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# #字典中的key值即为csv中列名\n",
    "# dataframe = pd.DataFrame({'Id':(test_data['Tweet']),'Predicted':prediction})\n",
    "\n",
    "# #将DataFrame存储为csv,index表示是否显示行名，default=True\n",
    "# dataframe.to_csv(\"ResultBOW5W.csv\",index=False,sep=',')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Id  Predicted\n",
      "1          1       4645\n",
      "2          2       5408\n",
      "3          3       5462\n",
      "4          4       4892\n",
      "5          5       9042\n",
      "6          6       4854\n",
      "7          7       5096\n",
      "8          8      12321\n",
      "9          9       4060\n",
      "10        10       6156\n",
      "11        11       4714\n",
      "12        12       1667\n",
      "13        13       4096\n",
      "14        14       4632\n",
      "15        15       4557\n",
      "16        16       4984\n",
      "17        17       1552\n",
      "18        18       4898\n",
      "19        19       4620\n",
      "20        20       6111\n",
      "21        21       5517\n",
      "22        22       1693\n",
      "23        23       7751\n",
      "24        24       9476\n",
      "25        25       8625\n",
      "26        26       5042\n",
      "27        27       4278\n",
      "28        28       8249\n",
      "29        29       5283\n",
      "30        30       5646\n",
      "...      ...        ...\n",
      "35408  35408       4767\n",
      "35409  35409       6274\n",
      "35410  35410       5286\n",
      "35411  35411       6324\n",
      "35412  35412       7895\n",
      "35413  35413       5619\n",
      "35414  35414       4999\n",
      "35415  35415       5186\n",
      "35416  35416       5428\n",
      "35417  35417       4539\n",
      "35418  35418       4371\n",
      "35419  35419       5347\n",
      "35420  35420       4860\n",
      "35421  35421       5182\n",
      "35422  35422       5184\n",
      "35423  35423       5267\n",
      "35424  35424       5697\n",
      "35425  35425       4660\n",
      "35426  35426       4699\n",
      "35427  35427       8130\n",
      "35428  35428       4170\n",
      "35429  35429       5076\n",
      "35430  35430       5765\n",
      "35431  35431        -49\n",
      "35432  35432       4775\n",
      "35433  35433       5989\n",
      "35434  35434       4650\n",
      "35435  35435       4631\n",
      "35436  35436       5416\n",
      "35437  35437       5340\n",
      "\n",
      "[35437 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "test_data['Predicted'] = prediction.astype(int)\n",
    "submission = test_data[['Predicted']]\n",
    "submission.index = np.arange(1, len(submission) + 1)\n",
    "submission['Id'] = submission.index\n",
    "\n",
    "columnsTitles=[\"Id\",\"Predicted\"]\n",
    "submission=submission.reindex(columns=columnsTitles)\n",
    "submission.to_csv('ResultTFIDF5WLM.csv',index=0)\n",
    "print(submission)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Predicted\n",
      "0       4645.997578\n",
      "1       5408.374227\n",
      "2       5462.982105\n",
      "3       4892.520948\n",
      "4       9042.911872\n",
      "5       4854.156668\n",
      "6       5096.802575\n",
      "7      12321.233851\n",
      "8       4060.629854\n",
      "9       6156.664774\n",
      "10      4714.854287\n",
      "11      1667.011024\n",
      "12      4096.345543\n",
      "13      4632.670831\n",
      "14      4557.559665\n",
      "15      4984.087507\n",
      "16      1552.634439\n",
      "17      4898.893118\n",
      "18      4620.176630\n",
      "19      6111.766211\n",
      "20      5517.778820\n",
      "21      1693.899452\n",
      "22      7751.033454\n",
      "23      9476.806597\n",
      "24      8625.523601\n",
      "25      5042.852260\n",
      "26      4278.989251\n",
      "27      8249.694295\n",
      "28      5283.916934\n",
      "29      5646.351193\n",
      "...             ...\n",
      "35407   4767.917163\n",
      "35408   6274.286037\n",
      "35409   5286.080007\n",
      "35410   6324.226278\n",
      "35411   7895.599125\n",
      "35412   5619.388144\n",
      "35413   4999.398574\n",
      "35414   5186.847823\n",
      "35415   5428.785040\n",
      "35416   4539.113625\n",
      "35417   4371.570708\n",
      "35418   5347.623083\n",
      "35419   4860.862531\n",
      "35420   5182.471421\n",
      "35421   5184.072743\n",
      "35422   5267.348379\n",
      "35423   5697.644406\n",
      "35424   4660.084908\n",
      "35425   4699.156973\n",
      "35426   8130.368160\n",
      "35427   4170.947820\n",
      "35428   5076.013721\n",
      "35429   5765.930440\n",
      "35430    -49.079712\n",
      "35431   4775.867624\n",
      "35432   5989.904198\n",
      "35433   4650.853350\n",
      "35434   4631.133818\n",
      "35435   5416.927781\n",
      "35436   5340.598429\n",
      "\n",
      "[35437 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "test_data['Predicted'] = prediction\n",
    "submission = test_data[['Predicted']]\n",
    "# submission['Id'] = submission.index\n",
    "# submission.index = np.arange(1, len(submission) + 1)\n",
    "\n",
    "\n",
    "\n",
    "# submission = pd.write_csv('ResultBOW5W.csv', names = ['Id', 'Predicted'])\n",
    "submission.to_csv('Resulttfidflm5W.csv',index=0)\n",
    "print(submission)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
