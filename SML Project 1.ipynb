{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COMP90051 Authorship Attribution \n",
    "----------\n",
    "    \n",
    "`1.` [Loading Data](#loading)\n",
    "\n",
    "    1.1 Loading Packages\n",
    "    1.2 Loading Train, Test\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"loading\"></a>\n",
    "# Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re, pickle, os, string\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import nltk\n",
    "import string\n",
    "import spacy\n",
    "from profanity import profanity\n",
    "from nltk.corpus import stopwords\n",
    "from spacy.util import compile_prefix_regex, compile_infix_regex, compile_suffix_regex\n",
    "from spacy.tokenizer import Tokenizer\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style('whitegrid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Author                                              Tweet\n",
      "0         8746     @handle Let's try and catch up live next week!\n",
      "1         8746  Going to watch Grey's on the big screen - Thur...\n",
      "2         8746  @handle My pleasure Patrick....hope you are well!\n",
      "3         8746  @handle Hi there! Been traveling a lot and lot...\n",
      "4         8746  RT @handle Looking to Drink Clean & Go Green? ...\n",
      "5         8746  RT @handle: Ft. Hood officials confirm the 2 o...\n",
      "6         8746  RT @handle: Mickey Mouse is Getting a Make Ove...\n",
      "7         8746           @handle How did u get the invite Justin?\n",
      "8         8746  @handle I think I am still a good friend of he...\n",
      "9         8746  @handle I remember! I am fine - how are u? Wha...\n",
      "10        8746     @handle That's great - good for the coach!!!!!\n",
      "11        8746  @handle I don't want to picture u sitting on i...\n",
      "12        8746  @handle D- Thanks for the RTs....are you going...\n",
      "13        8746           @handle Grrr....you must be going crazy!\n",
      "14        8746  @handle Hi there - just catching up from my tr...\n",
      "15        8746  RT @handle: If you're looking for some great l...\n",
      "16        8746  RT @handle: Retailers who aren’t engaging cust...\n",
      "17        8746  RT @handle: Director of Global Brand Marketing...\n",
      "18        8746  Still in car....want to jump out....45 minutes...\n",
      "19        8746  RT @handle: \"Only surround yourself with peopl...\n",
      "20        8746  @handle wish I could but 24/7 w stu's family t...\n",
      "21        8746  RT @handle: Help us help MusiCares! Vote for C...\n",
      "22        8746                     @handle yum!!!! Save me some!!\n",
      "23        8746  RT @handle: Gratitude is the sign of noble sou...\n",
      "24        8746           @handle I don't think I know what it is!\n",
      "25        8746  RT @handle: @handle Just found you via @handle...\n",
      "26        8746  RT @handle: RT @handle: Travelling for the Hol...\n",
      "27        8746       Just entering ohio - special hi to @handle!!\n",
      "28        8746  @handle well we agree on one food thing friend...\n",
      "29        8746                                @handle only 1!!!!!\n",
      "...        ...                                                ...\n",
      "328165    1319                                            @handle\n",
      "328166    1319  @handle Please add me to the #awsms09 afterpar...\n",
      "328167    1319  @handle great party last night...met some tale...\n",
      "328168    1319  Alta Phoenix Lofts #1 Phoenix!!!!! Congrats to...\n",
      "328169    9235                You manage things; you lead people.\n",
      "328170    9235  Not to know is bad; not to wish to know is worse.\n",
      "328171    9235  That there should one man die ignorant who had...\n",
      "328172    9235                       Will is character in action.\n",
      "328173    9235     What the mind dwells upon, the body acts upon.\n",
      "328174    9235      Success as I see it, is a result, not a goal.\n",
      "328175    9235  All generalizations are false, including this ...\n",
      "328176    9235  It is the province of knowledge to speak and i...\n",
      "328177    9235  A leader, once convinced that a particular cou...\n",
      "328178    9235  You can not make excuses and money at the same...\n",
      "328179    4357  Henry Brothers Electronics, Inc. to Participat...\n",
      "328180    4357  TechInsights' ESC UK Event Showcases Leading C...\n",
      "328181    4357  DEMOfall 09 Announces Lineup of Emerging Techn...\n",
      "328182    4357  AFP Hosts Symposium on Essentials for Doing Bu...\n",
      "328183    4357  AlertEnterprise Wins ASIS Accolades 2009 Secur...\n",
      "328184    4357  Andrews International Introduces New Methodolo...\n",
      "328185    4357  Innovation Strong Despite Recession: Human Res...\n",
      "328186    4357  VideoIQ and Milestone Systems Partner to Deliv...\n",
      "328187    4357  Phoenix Technologies to Showcase Cutting Edge ...\n",
      "328188    4357  AnyDATA's APT-210 Tracking Device Measures Att...\n",
      "328189    4357  Samplify Systems Announces Distribution Agreem...\n",
      "328190    4357  Steelbox Demonstrates Open Video Framework wit...\n",
      "328191    4357  Small Businesses Rely on Sage to Help Them Rid...\n",
      "328192    4357  TimeSight Systems™ Announces Next-Generation P...\n",
      "328193    4357  Diebold Makes Its Leading Monitoring Solutions...\n",
      "328194    4357  GVI Security Solutions to Introduce AutoIP™ VM...\n",
      "\n",
      "[328195 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "train_data = None\n",
    "test_data = None\n",
    "\n",
    "def load_data():\n",
    "    global train_data, test_data\n",
    "    train_data = pd.read_csv('train_tweets.txt', delimiter=\"\\t\", header=None)\n",
    "    test_data = pd.read_csv('test_tweets_unlabeled.txt', delimiter=\"\\t\", header = None)\n",
    "\n",
    "load_data()\n",
    "train_data.columns = ['Author', 'Tweet']\n",
    "print(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pickle(filepath):\n",
    "    documents_f = open(filepath, 'rb')\n",
    "    file = pickle.load(documents_f)\n",
    "    documents_f.close()\n",
    "    \n",
    "    return file\n",
    "\n",
    "def save_pickle(data, filepath):\n",
    "    save_documents = open(filepath, 'wb')\n",
    "    pickle.dump(data, save_documents)\n",
    "    save_documents.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_tokenizer(nlp):\n",
    "    infix_re = re.compile(r'''[.\\?\\:\\;\\...\\‘\\’\\`\\“\\”\\\"\\'~]''')\n",
    "    prefix_re = compile_prefix_regex(nlp.Defaults.prefixes)\n",
    "    suffix_re = compile_suffix_regex(nlp.Defaults.suffixes)\n",
    "\n",
    "    return Tokenizer(nlp.vocab, prefix_search=prefix_re.search,\n",
    "                                suffix_search=suffix_re.search,\n",
    "                                infix_finditer=infix_re.finditer,\n",
    "                                token_match=None)\n",
    "spacy_nlp = spacy.load(\"en\")\n",
    "spacy_nlp.tokenizer = custom_tokenizer(spacy_nlp)\n",
    "nlp1 = spacy.load('en_core_web_lg')\n",
    "\n",
    "stp = [word for word in list(stopwords.words('english') + [ \"'s\", \"'m\", \"ca\"])\n",
    "        if word not in [\"no\", \"not\"] and word.rfind(\"n't\") == -1]\n",
    "\n",
    "class PreProcessor(object):\n",
    "    '''Pre-processor which cleans text, lemmatises, removes stop words and punctuation, \n",
    "    returns df of processed text.'''\n",
    "\n",
    "    def __init__(self):\n",
    "        self._stopWordList = stp\n",
    "        self._punct_removal = list(string.punctuation)\n",
    "        self.sid = SentimentIntensityAnalyzer()\n",
    "\n",
    "    def _tokenize_text(self, sample):\n",
    "        '''tokenises sentences in order to lemmatise, remove stop words and punctuation, \n",
    "        returns string of processed text'''\n",
    "\n",
    "        # get tokens using spacy\n",
    "        tokens = spacy_nlp(sample)\n",
    "\n",
    "        # lemmatising tokens\n",
    "        tokens = [t.lemma_.strip()\n",
    "                  if t.lemma_ != \"-PRON-\"\n",
    "                  else t.lower_\n",
    "                  for t in tokens]\n",
    "\n",
    "        # stopword and punctuation removal\n",
    "        tokens = [t.lower() for t in tokens\n",
    "                  if (t not in self._stopWordList and t not in self._punct_removal)]\n",
    "\n",
    "        processed_text = \" \".join(tokens)\n",
    "        return processed_text\n",
    "    \n",
    "    def remove_url(self, text):\n",
    "        result = re.sub(r\"http\\S+\", \"\", text)\n",
    "        return result\n",
    "    \n",
    "    def check_url(self, text):\n",
    "        url = re.findall('http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+', text) \n",
    "        if len(url) != 0:\n",
    "            return True\n",
    "        return False\n",
    "    \n",
    "    def unique_words(self, words):\n",
    "        word_count = len(words)\n",
    "        unique_count = len(set(words))\n",
    "        if word_count!=0:\n",
    "            return unique_count / word_count\n",
    "        return 0\n",
    "    \n",
    "    def mention(self, text):\n",
    "        return set([re.sub(r\"(\\W+)$\", \"\", j) for j in set([i for i in text.split() if i.startswith(\"@\")])])\n",
    "    \n",
    "    def retweet(self, text):\n",
    "        rt = 'rt'\n",
    "        if rt in text:\n",
    "            return True\n",
    "        return False\n",
    "    \n",
    "    def hashtag(self, text):\n",
    "        return set([re.sub(r\"(\\W+)$\", \"\", j) for j in set([i for i in text.split() if i.startswith(\"#\")])])\n",
    "    \n",
    "    def extract_emojis(self, text):\n",
    "        happy = [':-)', ':-D', ':)', ':o)', ':]', ':3', ':c)', ':>', '=]', '8)', '=)', ':}', ':^']\n",
    "        sad = [':-(', ':(', ':\\'-(', ':\\'(', ':\\'-)' ':\\')', ':-|', ':-', ':{', ':[', ':\\\\', ':*',':&', ':<']\n",
    "        for each in happy:\n",
    "            if each in text:\n",
    "                return 'Happy'\n",
    "                break\n",
    "                   \n",
    "        for each in sad:\n",
    "            if each in text:\n",
    "                return 'Sad'\n",
    "                break\n",
    "        return ''\n",
    "    \n",
    "    def profanity_analysis(self, content):\n",
    "        contain_profanity=profanity.contains_profanity(content)\n",
    "        return contain_profanity\n",
    "    \n",
    "    def location_finder(self, text):\n",
    "        doc = nlp1(text)\n",
    "        for ent in doc.ents:\n",
    "            if ent.label_ == 'GPE':\n",
    "                 return ent.text\n",
    "                 break\n",
    " \n",
    "    def transform_text(self, data):\n",
    "        \n",
    "        '''applies the clean and tokenise methods to the texts, \n",
    "        encodes the target variable to numerical. \n",
    "        Option to set pickle to True to save clean df'''\n",
    "        no_punct_translator=str.maketrans('','',string.punctuation)\n",
    "        \n",
    "        data['words'] = data['Tweet'].apply(lambda row: self.remove_url(str(row))).apply(lambda t: nltk.word_tokenize(t.translate(no_punct_translator).lower()))\n",
    "        data['URL'] = data['Tweet'].apply(lambda row: self.check_url(str(row)))\n",
    "        data['word_count'] = data['words'].apply(lambda words: len(words))\n",
    "        data['sentence_length'] = data['words'].apply(lambda w: sum(map(len, w)))\n",
    "        data['text_length'] = data['Tweet'].apply(lambda t: len(str(t)))\n",
    "        data['sentiment'] = data['Tweet'].apply(lambda t: self.sid.polarity_scores(t)['compound'])\n",
    "        data['punctuation_per_tweet'] = data['Tweet'].apply(lambda t: len(list(filter(lambda c: c in t, string.punctuation)))) / data['text_length']\n",
    "        data['unique_ratio'] = data['words'].apply(lambda row: self.unique_words(row))\n",
    "        data['avg_word_length'] = data['words'].apply(lambda words: sum(map(len, words)) / len(words) if len(words)!=0 else 0)\n",
    "        data['mention'] = data['Tweet'].apply(lambda row: self.mention(str(row)))\n",
    "        data['Retweet'] = data['words'].apply(lambda row: self.retweet(str(row)))\n",
    "        data['Hashtag'] = data['Tweet'].apply(lambda row: self.hashtag(str(row)))\n",
    "        data['emojis'] = data['Tweet'].apply(lambda row: self.extract_emojis(str(row)))\n",
    "        data['profanity'] = data['words'].apply(lambda row: self.profanity_analysis(str(row)))\n",
    "        data['location'] = data['Tweet'].apply(lambda row: self.location_finder(str(row)))\n",
    "        return data\n",
    "    \n",
    "    def transform_text1(self, data):\n",
    "        data['transform'] = data['words'].apply(lambda row: self._tokenize_text(str(row)))\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = load_pickle(\"train_data.p\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Author</th>\n",
       "      <th>Tweet</th>\n",
       "      <th>words</th>\n",
       "      <th>URL</th>\n",
       "      <th>word_count</th>\n",
       "      <th>sentence_length</th>\n",
       "      <th>text_length</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>punctuation_per_tweet</th>\n",
       "      <th>unique_ratio</th>\n",
       "      <th>avg_word_length</th>\n",
       "      <th>mention</th>\n",
       "      <th>Retweet</th>\n",
       "      <th>Hashtag</th>\n",
       "      <th>emojis</th>\n",
       "      <th>profanity</th>\n",
       "      <th>location</th>\n",
       "      <th>transform</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8746</td>\n",
       "      <td>@handle Let's try and catch up live next week!</td>\n",
       "      <td>[handle, lets, try, and, catch, up, live, next...</td>\n",
       "      <td>False</td>\n",
       "      <td>9</td>\n",
       "      <td>35</td>\n",
       "      <td>46</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.065217</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.888889</td>\n",
       "      <td>{@handle}</td>\n",
       "      <td>False</td>\n",
       "      <td>{}</td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>handle let try catch live next week</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8746</td>\n",
       "      <td>Going to watch Grey's on the big screen - Thur...</td>\n",
       "      <td>[going, to, watch, greys, on, the, big, screen...</td>\n",
       "      <td>False</td>\n",
       "      <td>10</td>\n",
       "      <td>49</td>\n",
       "      <td>66</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.045455</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.900000</td>\n",
       "      <td>{}</td>\n",
       "      <td>False</td>\n",
       "      <td>{}</td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>go watch grey big screen thursday indulgence</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8746</td>\n",
       "      <td>@handle My pleasure Patrick....hope you are well!</td>\n",
       "      <td>[handle, my, pleasure, patrickhope, you, are, ...</td>\n",
       "      <td>False</td>\n",
       "      <td>7</td>\n",
       "      <td>37</td>\n",
       "      <td>49</td>\n",
       "      <td>0.7263</td>\n",
       "      <td>0.061224</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.285714</td>\n",
       "      <td>{@handle}</td>\n",
       "      <td>False</td>\n",
       "      <td>{}</td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>handle pleasure patrickhope well</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8746</td>\n",
       "      <td>@handle Hi there! Been traveling a lot and lot...</td>\n",
       "      <td>[handle, hi, there, been, traveling, a, lot, a...</td>\n",
       "      <td>False</td>\n",
       "      <td>25</td>\n",
       "      <td>100</td>\n",
       "      <td>132</td>\n",
       "      <td>0.4997</td>\n",
       "      <td>0.030303</td>\n",
       "      <td>0.960000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>{@handle}</td>\n",
       "      <td>False</td>\n",
       "      <td>{}</td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>handle hi travel lot lot come next month recov...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8746</td>\n",
       "      <td>RT @handle Looking to Drink Clean &amp; Go Green? ...</td>\n",
       "      <td>[rt, handle, looking, to, drink, clean, go, gr...</td>\n",
       "      <td>False</td>\n",
       "      <td>18</td>\n",
       "      <td>86</td>\n",
       "      <td>109</td>\n",
       "      <td>0.4019</td>\n",
       "      <td>0.036697</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>4.777778</td>\n",
       "      <td>{@handle}</td>\n",
       "      <td>True</td>\n",
       "      <td>{}</td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>rt handle look drink clean go green purchase c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>8746</td>\n",
       "      <td>RT @handle: Ft. Hood officials confirm the 2 o...</td>\n",
       "      <td>[rt, handle, ft, hood, officials, confirm, the...</td>\n",
       "      <td>False</td>\n",
       "      <td>17</td>\n",
       "      <td>86</td>\n",
       "      <td>105</td>\n",
       "      <td>-0.3400</td>\n",
       "      <td>0.028571</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.058824</td>\n",
       "      <td>{@handle}</td>\n",
       "      <td>True</td>\n",
       "      <td>{}</td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>rt handle ft hood official confirm 2 soldier i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>8746</td>\n",
       "      <td>RT @handle: Mickey Mouse is Getting a Make Ove...</td>\n",
       "      <td>[rt, handle, mickey, mouse, is, getting, a, ma...</td>\n",
       "      <td>True</td>\n",
       "      <td>10</td>\n",
       "      <td>43</td>\n",
       "      <td>76</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.052632</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>4.300000</td>\n",
       "      <td>{@handle}</td>\n",
       "      <td>True</td>\n",
       "      <td>{}</td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>rt handle mickey mouse get make handle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8746</td>\n",
       "      <td>@handle How did u get the invite Justin?</td>\n",
       "      <td>[handle, how, did, u, get, the, invite, justin]</td>\n",
       "      <td>False</td>\n",
       "      <td>8</td>\n",
       "      <td>31</td>\n",
       "      <td>40</td>\n",
       "      <td>0.1531</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.875000</td>\n",
       "      <td>{@handle}</td>\n",
       "      <td>False</td>\n",
       "      <td>{}</td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>handle u get invite justin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8746</td>\n",
       "      <td>@handle I think I am still a good friend of he...</td>\n",
       "      <td>[handle, i, think, i, am, still, a, good, frie...</td>\n",
       "      <td>False</td>\n",
       "      <td>12</td>\n",
       "      <td>40</td>\n",
       "      <td>55</td>\n",
       "      <td>0.8478</td>\n",
       "      <td>0.054545</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>{@handle}</td>\n",
       "      <td>False</td>\n",
       "      <td>{}</td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>handle think still good friend lol</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>8746</td>\n",
       "      <td>@handle I remember! I am fine - how are u? Wha...</td>\n",
       "      <td>[handle, i, remember, i, am, fine, how, are, u...</td>\n",
       "      <td>False</td>\n",
       "      <td>11</td>\n",
       "      <td>37</td>\n",
       "      <td>54</td>\n",
       "      <td>0.3510</td>\n",
       "      <td>0.092593</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>3.363636</td>\n",
       "      <td>{@handle}</td>\n",
       "      <td>False</td>\n",
       "      <td>{}</td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>handle remember fine u new</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>8746</td>\n",
       "      <td>@handle That's great - good for the coach!!!!!</td>\n",
       "      <td>[handle, thats, great, good, for, the, coach]</td>\n",
       "      <td>False</td>\n",
       "      <td>7</td>\n",
       "      <td>31</td>\n",
       "      <td>46</td>\n",
       "      <td>0.8469</td>\n",
       "      <td>0.086957</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.428571</td>\n",
       "      <td>{@handle}</td>\n",
       "      <td>False</td>\n",
       "      <td>{}</td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>handle great good coach</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>8746</td>\n",
       "      <td>@handle I don't want to picture u sitting on i...</td>\n",
       "      <td>[handle, i, dont, want, to, picture, u, sittin...</td>\n",
       "      <td>False</td>\n",
       "      <td>14</td>\n",
       "      <td>53</td>\n",
       "      <td>77</td>\n",
       "      <td>0.1996</td>\n",
       "      <td>0.051948</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>3.785714</td>\n",
       "      <td>{@handle}</td>\n",
       "      <td>False</td>\n",
       "      <td>{}</td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>handle dont want picture u sit lol understand</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>8746</td>\n",
       "      <td>@handle D- Thanks for the RTs....are you going...</td>\n",
       "      <td>[handle, d, thanks, for, the, rtsare, you, goi...</td>\n",
       "      <td>False</td>\n",
       "      <td>11</td>\n",
       "      <td>46</td>\n",
       "      <td>63</td>\n",
       "      <td>0.4404</td>\n",
       "      <td>0.063492</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.181818</td>\n",
       "      <td>{@handle}</td>\n",
       "      <td>True</td>\n",
       "      <td>{}</td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>handle thank rtsare go womma summit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>8746</td>\n",
       "      <td>@handle Grrr....you must be going crazy!</td>\n",
       "      <td>[handle, grrryou, must, be, going, crazy]</td>\n",
       "      <td>False</td>\n",
       "      <td>6</td>\n",
       "      <td>29</td>\n",
       "      <td>40</td>\n",
       "      <td>-0.4003</td>\n",
       "      <td>0.075000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.833333</td>\n",
       "      <td>{@handle}</td>\n",
       "      <td>False</td>\n",
       "      <td>{}</td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>handle grrryou must go crazy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>8746</td>\n",
       "      <td>@handle Hi there - just catching up from my tr...</td>\n",
       "      <td>[handle, hi, there, just, catching, up, from, ...</td>\n",
       "      <td>False</td>\n",
       "      <td>13</td>\n",
       "      <td>50</td>\n",
       "      <td>68</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.044118</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.846154</td>\n",
       "      <td>{@handle}</td>\n",
       "      <td>False</td>\n",
       "      <td>{}</td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>handle hi catch trip news dale</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>8746</td>\n",
       "      <td>RT @handle: If you're looking for some great l...</td>\n",
       "      <td>[rt, handle, if, youre, looking, for, some, gr...</td>\n",
       "      <td>True</td>\n",
       "      <td>15</td>\n",
       "      <td>63</td>\n",
       "      <td>105</td>\n",
       "      <td>0.6588</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.200000</td>\n",
       "      <td>{@handle}</td>\n",
       "      <td>True</td>\n",
       "      <td>{}</td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>rt handle youre look great list follow check mine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>8746</td>\n",
       "      <td>RT @handle: Retailers who aren’t engaging cust...</td>\n",
       "      <td>[rt, handle, retailers, who, aren, ’, t, engag...</td>\n",
       "      <td>True</td>\n",
       "      <td>17</td>\n",
       "      <td>82</td>\n",
       "      <td>117</td>\n",
       "      <td>0.0516</td>\n",
       "      <td>0.034188</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.823529</td>\n",
       "      <td>{@handle}</td>\n",
       "      <td>True</td>\n",
       "      <td>{}</td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>rt handle retailer ’ engage customer social me...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>8746</td>\n",
       "      <td>RT @handle: Director of Global Brand Marketing...</td>\n",
       "      <td>[rt, handle, director, of, global, brand, mark...</td>\n",
       "      <td>True</td>\n",
       "      <td>17</td>\n",
       "      <td>86</td>\n",
       "      <td>135</td>\n",
       "      <td>0.5423</td>\n",
       "      <td>0.081481</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.058824</td>\n",
       "      <td>{@handle}</td>\n",
       "      <td>True</td>\n",
       "      <td>{#jobs, #twitjobs}</td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>rt handle director global brand marketing hote...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>8746</td>\n",
       "      <td>Still in car....want to jump out....45 minutes...</td>\n",
       "      <td>[still, in, carwant, to, jump, out45, minutes,...</td>\n",
       "      <td>False</td>\n",
       "      <td>8</td>\n",
       "      <td>35</td>\n",
       "      <td>53</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.037736</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.375000</td>\n",
       "      <td>{}</td>\n",
       "      <td>False</td>\n",
       "      <td>{}</td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>still carwant jump out45 minute eta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>8746</td>\n",
       "      <td>RT @handle: \"Only surround yourself with peopl...</td>\n",
       "      <td>[rt, handle, only, surround, yourself, with, p...</td>\n",
       "      <td>False</td>\n",
       "      <td>15</td>\n",
       "      <td>81</td>\n",
       "      <td>101</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.049505</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.400000</td>\n",
       "      <td>{@handle}</td>\n",
       "      <td>True</td>\n",
       "      <td>{#inspiration}</td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>rt handle surround people lift high oprah winf...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>8746</td>\n",
       "      <td>@handle wish I could but 24/7 w stu's family t...</td>\n",
       "      <td>[handle, wish, i, could, but, 247, w, stus, fa...</td>\n",
       "      <td>False</td>\n",
       "      <td>22</td>\n",
       "      <td>77</td>\n",
       "      <td>107</td>\n",
       "      <td>-0.3400</td>\n",
       "      <td>0.065421</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>{@handle}</td>\n",
       "      <td>False</td>\n",
       "      <td>{}</td>\n",
       "      <td>Sad</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>handle wish could 247 w stus family drive home...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>8746</td>\n",
       "      <td>RT @handle: Help us help MusiCares! Vote for C...</td>\n",
       "      <td>[rt, handle, help, us, help, musicares, vote, ...</td>\n",
       "      <td>True</td>\n",
       "      <td>11</td>\n",
       "      <td>51</td>\n",
       "      <td>86</td>\n",
       "      <td>0.8172</td>\n",
       "      <td>0.058140</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>4.636364</td>\n",
       "      <td>{@handle}</td>\n",
       "      <td>True</td>\n",
       "      <td>{}</td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>rt handle help us help musicare vote charity f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>8746</td>\n",
       "      <td>@handle yum!!!! Save me some!!</td>\n",
       "      <td>[handle, yum, save, me, some]</td>\n",
       "      <td>False</td>\n",
       "      <td>5</td>\n",
       "      <td>19</td>\n",
       "      <td>30</td>\n",
       "      <td>0.6562</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.800000</td>\n",
       "      <td>{@handle}</td>\n",
       "      <td>False</td>\n",
       "      <td>{}</td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>handle yum save</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>8746</td>\n",
       "      <td>RT @handle: Gratitude is the sign of noble sou...</td>\n",
       "      <td>[rt, handle, gratitude, is, the, sign, of, nob...</td>\n",
       "      <td>False</td>\n",
       "      <td>12</td>\n",
       "      <td>57</td>\n",
       "      <td>74</td>\n",
       "      <td>0.7430</td>\n",
       "      <td>0.067568</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>4.750000</td>\n",
       "      <td>{@handle}</td>\n",
       "      <td>True</td>\n",
       "      <td>{#gratitude, #quote}</td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>rt handle gratitude sign noble soul aesop quot...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>8746</td>\n",
       "      <td>@handle I don't think I know what it is!</td>\n",
       "      <td>[handle, i, dont, think, i, know, what, it, is]</td>\n",
       "      <td>False</td>\n",
       "      <td>9</td>\n",
       "      <td>29</td>\n",
       "      <td>40</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.075000</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>3.222222</td>\n",
       "      <td>{@handle}</td>\n",
       "      <td>False</td>\n",
       "      <td>{}</td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>handle dont think know</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>8746</td>\n",
       "      <td>RT @handle: @handle Just found you via @handle...</td>\n",
       "      <td>[rt, handle, handle, just, found, you, via, ha...</td>\n",
       "      <td>False</td>\n",
       "      <td>23</td>\n",
       "      <td>91</td>\n",
       "      <td>121</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.041322</td>\n",
       "      <td>0.869565</td>\n",
       "      <td>3.956522</td>\n",
       "      <td>{@handle}</td>\n",
       "      <td>True</td>\n",
       "      <td>{}</td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>rt handle handle find via handle sheesh handle...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>8746</td>\n",
       "      <td>RT @handle: RT @handle: Travelling for the Hol...</td>\n",
       "      <td>[rt, handle, rt, handle, travelling, for, the,...</td>\n",
       "      <td>True</td>\n",
       "      <td>18</td>\n",
       "      <td>76</td>\n",
       "      <td>124</td>\n",
       "      <td>0.4574</td>\n",
       "      <td>0.048387</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>4.222222</td>\n",
       "      <td>{@handle}</td>\n",
       "      <td>True</td>\n",
       "      <td>{}</td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>rt handle rt handle travel holiday send us pic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>8746</td>\n",
       "      <td>Just entering ohio - special hi to @handle!!</td>\n",
       "      <td>[just, entering, ohio, special, hi, to, handle]</td>\n",
       "      <td>False</td>\n",
       "      <td>7</td>\n",
       "      <td>33</td>\n",
       "      <td>44</td>\n",
       "      <td>0.5080</td>\n",
       "      <td>0.068182</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.714286</td>\n",
       "      <td>{@handle}</td>\n",
       "      <td>False</td>\n",
       "      <td>{}</td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "      <td>ohio</td>\n",
       "      <td>enter ohio special hi handle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>8746</td>\n",
       "      <td>@handle well we agree on one food thing friend...</td>\n",
       "      <td>[handle, well, we, agree, on, one, food, thing...</td>\n",
       "      <td>False</td>\n",
       "      <td>19</td>\n",
       "      <td>81</td>\n",
       "      <td>106</td>\n",
       "      <td>0.8777</td>\n",
       "      <td>0.056604</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.263158</td>\n",
       "      <td>{@handle}</td>\n",
       "      <td>False</td>\n",
       "      <td>{#tweetsgiving}</td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>handle well agree one food thing friend pumpki...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>8746</td>\n",
       "      <td>@handle only 1!!!!!</td>\n",
       "      <td>[handle, only, 1]</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>19</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.105263</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.666667</td>\n",
       "      <td>{@handle}</td>\n",
       "      <td>False</td>\n",
       "      <td>{}</td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>handle 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>328165</th>\n",
       "      <td>1319</td>\n",
       "      <td>@handle</td>\n",
       "      <td>[handle]</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>{@handle}</td>\n",
       "      <td>False</td>\n",
       "      <td>{}</td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>handle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>328166</th>\n",
       "      <td>1319</td>\n",
       "      <td>@handle Please add me to the #awsms09 afterpar...</td>\n",
       "      <td>[handle, please, add, me, to, the, awsms09, af...</td>\n",
       "      <td>False</td>\n",
       "      <td>9</td>\n",
       "      <td>45</td>\n",
       "      <td>56</td>\n",
       "      <td>0.6369</td>\n",
       "      <td>0.053571</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>{@handle}</td>\n",
       "      <td>True</td>\n",
       "      <td>{#awsms09}</td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>handle please add awsms09 afterparty thank</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>328167</th>\n",
       "      <td>1319</td>\n",
       "      <td>@handle great party last night...met some tale...</td>\n",
       "      <td>[handle, great, party, last, nightmet, some, t...</td>\n",
       "      <td>False</td>\n",
       "      <td>8</td>\n",
       "      <td>46</td>\n",
       "      <td>57</td>\n",
       "      <td>0.8779</td>\n",
       "      <td>0.035088</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.750000</td>\n",
       "      <td>{@handle}</td>\n",
       "      <td>True</td>\n",
       "      <td>{}</td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>handle great party last nightmet talented people</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>328168</th>\n",
       "      <td>1319</td>\n",
       "      <td>Alta Phoenix Lofts #1 Phoenix!!!!! Congrats to...</td>\n",
       "      <td>[alta, phoenix, lofts, 1, phoenix, congrats, t...</td>\n",
       "      <td>True</td>\n",
       "      <td>9</td>\n",
       "      <td>45</td>\n",
       "      <td>79</td>\n",
       "      <td>0.6776</td>\n",
       "      <td>0.063291</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>{}</td>\n",
       "      <td>False</td>\n",
       "      <td>{#1}</td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>alta phoenix loft 1 phoenix congrat involve</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>328169</th>\n",
       "      <td>9235</td>\n",
       "      <td>You manage things; you lead people.</td>\n",
       "      <td>[you, manage, things, you, lead, people]</td>\n",
       "      <td>False</td>\n",
       "      <td>6</td>\n",
       "      <td>28</td>\n",
       "      <td>35</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.057143</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>4.666667</td>\n",
       "      <td>{}</td>\n",
       "      <td>False</td>\n",
       "      <td>{}</td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>manage thing lead people</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>328170</th>\n",
       "      <td>9235</td>\n",
       "      <td>Not to know is bad; not to wish to know is worse.</td>\n",
       "      <td>[not, to, know, is, bad, not, to, wish, to, kn...</td>\n",
       "      <td>False</td>\n",
       "      <td>12</td>\n",
       "      <td>36</td>\n",
       "      <td>49</td>\n",
       "      <td>-0.8342</td>\n",
       "      <td>0.040816</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>{}</td>\n",
       "      <td>False</td>\n",
       "      <td>{}</td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>not know bad not wish know bad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>328171</th>\n",
       "      <td>9235</td>\n",
       "      <td>That there should one man die ignorant who had...</td>\n",
       "      <td>[that, there, should, one, man, die, ignorant,...</td>\n",
       "      <td>False</td>\n",
       "      <td>17</td>\n",
       "      <td>75</td>\n",
       "      <td>93</td>\n",
       "      <td>-0.8860</td>\n",
       "      <td>0.021505</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.411765</td>\n",
       "      <td>{}</td>\n",
       "      <td>False</td>\n",
       "      <td>{}</td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>one man die ignorant capacity knowledge call t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>328172</th>\n",
       "      <td>9235</td>\n",
       "      <td>Will is character in action.</td>\n",
       "      <td>[will, is, character, in, action]</td>\n",
       "      <td>False</td>\n",
       "      <td>5</td>\n",
       "      <td>23</td>\n",
       "      <td>28</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.035714</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.600000</td>\n",
       "      <td>{}</td>\n",
       "      <td>False</td>\n",
       "      <td>{}</td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>character action</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>328173</th>\n",
       "      <td>9235</td>\n",
       "      <td>What the mind dwells upon, the body acts upon.</td>\n",
       "      <td>[what, the, mind, dwells, upon, the, body, act...</td>\n",
       "      <td>False</td>\n",
       "      <td>9</td>\n",
       "      <td>36</td>\n",
       "      <td>46</td>\n",
       "      <td>-0.0258</td>\n",
       "      <td>0.043478</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>{}</td>\n",
       "      <td>False</td>\n",
       "      <td>{}</td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>mind dwell upon body act upon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>328174</th>\n",
       "      <td>9235</td>\n",
       "      <td>Success as I see it, is a result, not a goal.</td>\n",
       "      <td>[success, as, i, see, it, is, a, result, not, ...</td>\n",
       "      <td>False</td>\n",
       "      <td>11</td>\n",
       "      <td>32</td>\n",
       "      <td>45</td>\n",
       "      <td>0.5719</td>\n",
       "      <td>0.044444</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>2.909091</td>\n",
       "      <td>{}</td>\n",
       "      <td>False</td>\n",
       "      <td>{}</td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>success see result not goal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>328175</th>\n",
       "      <td>9235</td>\n",
       "      <td>All generalizations are false, including this ...</td>\n",
       "      <td>[all, generalizations, are, false, including, ...</td>\n",
       "      <td>False</td>\n",
       "      <td>7</td>\n",
       "      <td>42</td>\n",
       "      <td>50</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.040000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>{}</td>\n",
       "      <td>False</td>\n",
       "      <td>{}</td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>generalization false include one</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>328176</th>\n",
       "      <td>9235</td>\n",
       "      <td>It is the province of knowledge to speak and i...</td>\n",
       "      <td>[it, is, the, province, of, knowledge, to, spe...</td>\n",
       "      <td>False</td>\n",
       "      <td>17</td>\n",
       "      <td>68</td>\n",
       "      <td>85</td>\n",
       "      <td>0.7096</td>\n",
       "      <td>0.011765</td>\n",
       "      <td>0.705882</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>{}</td>\n",
       "      <td>False</td>\n",
       "      <td>{}</td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>province knowledge speak privilege wisdom listen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>328177</th>\n",
       "      <td>9235</td>\n",
       "      <td>A leader, once convinced that a particular cou...</td>\n",
       "      <td>[a, leader, once, convinced, that, a, particul...</td>\n",
       "      <td>False</td>\n",
       "      <td>21</td>\n",
       "      <td>98</td>\n",
       "      <td>125</td>\n",
       "      <td>0.2960</td>\n",
       "      <td>0.016000</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>4.666667</td>\n",
       "      <td>{}</td>\n",
       "      <td>True</td>\n",
       "      <td>{}</td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>leader convinced particular course action righ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>328178</th>\n",
       "      <td>9235</td>\n",
       "      <td>You can not make excuses and money at the same...</td>\n",
       "      <td>[you, can, not, make, excuses, and, money, at,...</td>\n",
       "      <td>False</td>\n",
       "      <td>11</td>\n",
       "      <td>41</td>\n",
       "      <td>52</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.019231</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.727273</td>\n",
       "      <td>{}</td>\n",
       "      <td>False</td>\n",
       "      <td>{}</td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>not make excuse money time</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>328179</th>\n",
       "      <td>4357</td>\n",
       "      <td>Henry Brothers Electronics, Inc. to Participat...</td>\n",
       "      <td>[henry, brothers, electronics, inc, to, partic...</td>\n",
       "      <td>True</td>\n",
       "      <td>13</td>\n",
       "      <td>80</td>\n",
       "      <td>118</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.050847</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.153846</td>\n",
       "      <td>{}</td>\n",
       "      <td>True</td>\n",
       "      <td>{#tradeshow}</td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>henry brother electronic inc participate asis ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>328180</th>\n",
       "      <td>4357</td>\n",
       "      <td>TechInsights' ESC UK Event Showcases Leading C...</td>\n",
       "      <td>[techinsights, esc, uk, event, showcases, lead...</td>\n",
       "      <td>True</td>\n",
       "      <td>15</td>\n",
       "      <td>99</td>\n",
       "      <td>135</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.037037</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.600000</td>\n",
       "      <td>{}</td>\n",
       "      <td>False</td>\n",
       "      <td>{#tradeshow}</td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "      <td>UK</td>\n",
       "      <td>techinsight esc uk event showcase lead company...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>328181</th>\n",
       "      <td>4357</td>\n",
       "      <td>DEMOfall 09 Announces Lineup of Emerging Techn...</td>\n",
       "      <td>[demofall, 09, announces, lineup, of, emerging...</td>\n",
       "      <td>True</td>\n",
       "      <td>17</td>\n",
       "      <td>95</td>\n",
       "      <td>134</td>\n",
       "      <td>0.4404</td>\n",
       "      <td>0.029851</td>\n",
       "      <td>0.941176</td>\n",
       "      <td>5.588235</td>\n",
       "      <td>{}</td>\n",
       "      <td>False</td>\n",
       "      <td>{#tradeshow}</td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>demofall 09 announce lineup emerge technology ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>328182</th>\n",
       "      <td>4357</td>\n",
       "      <td>AFP Hosts Symposium on Essentials for Doing Bu...</td>\n",
       "      <td>[afp, hosts, symposium, on, essentials, for, d...</td>\n",
       "      <td>True</td>\n",
       "      <td>11</td>\n",
       "      <td>61</td>\n",
       "      <td>92</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.043478</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.545455</td>\n",
       "      <td>{}</td>\n",
       "      <td>False</td>\n",
       "      <td>{#tradeshow}</td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "      <td>China</td>\n",
       "      <td>afp host symposium essential business china tr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>328183</th>\n",
       "      <td>4357</td>\n",
       "      <td>AlertEnterprise Wins ASIS Accolades 2009 Secur...</td>\n",
       "      <td>[alertenterprise, wins, asis, accolades, 2009,...</td>\n",
       "      <td>True</td>\n",
       "      <td>10</td>\n",
       "      <td>69</td>\n",
       "      <td>101</td>\n",
       "      <td>0.9451</td>\n",
       "      <td>0.049505</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.900000</td>\n",
       "      <td>{}</td>\n",
       "      <td>True</td>\n",
       "      <td>{#tradeshow}</td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>alertenterprise win asis accolade 2009 securit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>328184</th>\n",
       "      <td>4357</td>\n",
       "      <td>Andrews International Introduces New Methodolo...</td>\n",
       "      <td>[andrews, international, introduces, new, meth...</td>\n",
       "      <td>True</td>\n",
       "      <td>13</td>\n",
       "      <td>99</td>\n",
       "      <td>135</td>\n",
       "      <td>0.6369</td>\n",
       "      <td>0.029630</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>7.615385</td>\n",
       "      <td>{}</td>\n",
       "      <td>False</td>\n",
       "      <td>{#tradeshow}</td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>andrew international introduce new methodology...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>328185</th>\n",
       "      <td>4357</td>\n",
       "      <td>Innovation Strong Despite Recession: Human Res...</td>\n",
       "      <td>[innovation, strong, despite, recession, human...</td>\n",
       "      <td>True</td>\n",
       "      <td>14</td>\n",
       "      <td>97</td>\n",
       "      <td>135</td>\n",
       "      <td>0.8192</td>\n",
       "      <td>0.029630</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.928571</td>\n",
       "      <td>{}</td>\n",
       "      <td>False</td>\n",
       "      <td>{#tradeshow}</td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>innovation strong despite recession human reso...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>328186</th>\n",
       "      <td>4357</td>\n",
       "      <td>VideoIQ and Milestone Systems Partner to Deliv...</td>\n",
       "      <td>[videoiq, and, milestone, systems, partner, to...</td>\n",
       "      <td>True</td>\n",
       "      <td>12</td>\n",
       "      <td>89</td>\n",
       "      <td>122</td>\n",
       "      <td>0.4588</td>\n",
       "      <td>0.040984</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>7.416667</td>\n",
       "      <td>{}</td>\n",
       "      <td>True</td>\n",
       "      <td>{#tradeshow}</td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>videoiq milestone system partner deliver integ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>328187</th>\n",
       "      <td>4357</td>\n",
       "      <td>Phoenix Technologies to Showcase Cutting Edge ...</td>\n",
       "      <td>[phoenix, technologies, to, showcase, cutting,...</td>\n",
       "      <td>True</td>\n",
       "      <td>14</td>\n",
       "      <td>93</td>\n",
       "      <td>134</td>\n",
       "      <td>-0.1280</td>\n",
       "      <td>0.044776</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>6.642857</td>\n",
       "      <td>{}</td>\n",
       "      <td>False</td>\n",
       "      <td>{#tradeshow}</td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>phoenix technology showcase cut edge technolog...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>328188</th>\n",
       "      <td>4357</td>\n",
       "      <td>AnyDATA's APT-210 Tracking Device Measures Att...</td>\n",
       "      <td>[anydatas, apt210, tracking, device, measures,...</td>\n",
       "      <td>True</td>\n",
       "      <td>11</td>\n",
       "      <td>73</td>\n",
       "      <td>108</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.636364</td>\n",
       "      <td>{}</td>\n",
       "      <td>False</td>\n",
       "      <td>{#tradeshow}</td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>anydatas apt210 tracking device measure attemp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>328189</th>\n",
       "      <td>4357</td>\n",
       "      <td>Samplify Systems Announces Distribution Agreem...</td>\n",
       "      <td>[samplify, systems, announces, distribution, a...</td>\n",
       "      <td>True</td>\n",
       "      <td>15</td>\n",
       "      <td>97</td>\n",
       "      <td>134</td>\n",
       "      <td>0.7003</td>\n",
       "      <td>0.029851</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.466667</td>\n",
       "      <td>{}</td>\n",
       "      <td>False</td>\n",
       "      <td>{#tradeshow}</td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>samplify system announce distribution agreemen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>328190</th>\n",
       "      <td>4357</td>\n",
       "      <td>Steelbox Demonstrates Open Video Framework wit...</td>\n",
       "      <td>[steelbox, demonstrates, open, video, framewor...</td>\n",
       "      <td>True</td>\n",
       "      <td>13</td>\n",
       "      <td>99</td>\n",
       "      <td>132</td>\n",
       "      <td>0.1779</td>\n",
       "      <td>0.030303</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>7.615385</td>\n",
       "      <td>{}</td>\n",
       "      <td>False</td>\n",
       "      <td>{#tradeshow}</td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>steelbox demonstrate open video framework sri ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>328191</th>\n",
       "      <td>4357</td>\n",
       "      <td>Small Businesses Rely on Sage to Help Them Rid...</td>\n",
       "      <td>[small, businesses, rely, on, sage, to, help, ...</td>\n",
       "      <td>True</td>\n",
       "      <td>13</td>\n",
       "      <td>63</td>\n",
       "      <td>96</td>\n",
       "      <td>-0.0258</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.846154</td>\n",
       "      <td>{}</td>\n",
       "      <td>False</td>\n",
       "      <td>{#tradeshow}</td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>small business rely sage help ride recession t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>328192</th>\n",
       "      <td>4357</td>\n",
       "      <td>TimeSight Systems™ Announces Next-Generation P...</td>\n",
       "      <td>[timesight, systems™, announces, nextgeneratio...</td>\n",
       "      <td>True</td>\n",
       "      <td>12</td>\n",
       "      <td>93</td>\n",
       "      <td>129</td>\n",
       "      <td>0.4588</td>\n",
       "      <td>0.038760</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>7.750000</td>\n",
       "      <td>{}</td>\n",
       "      <td>False</td>\n",
       "      <td>{#tradeshow}</td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>timesight system ™ announce nextgeneration pla...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>328193</th>\n",
       "      <td>4357</td>\n",
       "      <td>Diebold Makes Its Leading Monitoring Solutions...</td>\n",
       "      <td>[diebold, makes, its, leading, monitoring, sol...</td>\n",
       "      <td>True</td>\n",
       "      <td>10</td>\n",
       "      <td>68</td>\n",
       "      <td>99</td>\n",
       "      <td>0.1779</td>\n",
       "      <td>0.040404</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.800000</td>\n",
       "      <td>{}</td>\n",
       "      <td>False</td>\n",
       "      <td>{#tradeshow}</td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>diebold make lead monitoring solution availabl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>328194</th>\n",
       "      <td>4357</td>\n",
       "      <td>GVI Security Solutions to Introduce AutoIP™ VM...</td>\n",
       "      <td>[gvi, security, solutions, to, introduce, auto...</td>\n",
       "      <td>True</td>\n",
       "      <td>15</td>\n",
       "      <td>91</td>\n",
       "      <td>128</td>\n",
       "      <td>0.4767</td>\n",
       "      <td>0.031250</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.066667</td>\n",
       "      <td>{}</td>\n",
       "      <td>False</td>\n",
       "      <td>{#tradeshow}</td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>gvi security solution introduce autoip ™ vms i...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>328195 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Author                                              Tweet  \\\n",
       "0         8746     @handle Let's try and catch up live next week!   \n",
       "1         8746  Going to watch Grey's on the big screen - Thur...   \n",
       "2         8746  @handle My pleasure Patrick....hope you are well!   \n",
       "3         8746  @handle Hi there! Been traveling a lot and lot...   \n",
       "4         8746  RT @handle Looking to Drink Clean & Go Green? ...   \n",
       "5         8746  RT @handle: Ft. Hood officials confirm the 2 o...   \n",
       "6         8746  RT @handle: Mickey Mouse is Getting a Make Ove...   \n",
       "7         8746           @handle How did u get the invite Justin?   \n",
       "8         8746  @handle I think I am still a good friend of he...   \n",
       "9         8746  @handle I remember! I am fine - how are u? Wha...   \n",
       "10        8746     @handle That's great - good for the coach!!!!!   \n",
       "11        8746  @handle I don't want to picture u sitting on i...   \n",
       "12        8746  @handle D- Thanks for the RTs....are you going...   \n",
       "13        8746           @handle Grrr....you must be going crazy!   \n",
       "14        8746  @handle Hi there - just catching up from my tr...   \n",
       "15        8746  RT @handle: If you're looking for some great l...   \n",
       "16        8746  RT @handle: Retailers who aren’t engaging cust...   \n",
       "17        8746  RT @handle: Director of Global Brand Marketing...   \n",
       "18        8746  Still in car....want to jump out....45 minutes...   \n",
       "19        8746  RT @handle: \"Only surround yourself with peopl...   \n",
       "20        8746  @handle wish I could but 24/7 w stu's family t...   \n",
       "21        8746  RT @handle: Help us help MusiCares! Vote for C...   \n",
       "22        8746                     @handle yum!!!! Save me some!!   \n",
       "23        8746  RT @handle: Gratitude is the sign of noble sou...   \n",
       "24        8746           @handle I don't think I know what it is!   \n",
       "25        8746  RT @handle: @handle Just found you via @handle...   \n",
       "26        8746  RT @handle: RT @handle: Travelling for the Hol...   \n",
       "27        8746       Just entering ohio - special hi to @handle!!   \n",
       "28        8746  @handle well we agree on one food thing friend...   \n",
       "29        8746                                @handle only 1!!!!!   \n",
       "...        ...                                                ...   \n",
       "328165    1319                                            @handle   \n",
       "328166    1319  @handle Please add me to the #awsms09 afterpar...   \n",
       "328167    1319  @handle great party last night...met some tale...   \n",
       "328168    1319  Alta Phoenix Lofts #1 Phoenix!!!!! Congrats to...   \n",
       "328169    9235                You manage things; you lead people.   \n",
       "328170    9235  Not to know is bad; not to wish to know is worse.   \n",
       "328171    9235  That there should one man die ignorant who had...   \n",
       "328172    9235                       Will is character in action.   \n",
       "328173    9235     What the mind dwells upon, the body acts upon.   \n",
       "328174    9235      Success as I see it, is a result, not a goal.   \n",
       "328175    9235  All generalizations are false, including this ...   \n",
       "328176    9235  It is the province of knowledge to speak and i...   \n",
       "328177    9235  A leader, once convinced that a particular cou...   \n",
       "328178    9235  You can not make excuses and money at the same...   \n",
       "328179    4357  Henry Brothers Electronics, Inc. to Participat...   \n",
       "328180    4357  TechInsights' ESC UK Event Showcases Leading C...   \n",
       "328181    4357  DEMOfall 09 Announces Lineup of Emerging Techn...   \n",
       "328182    4357  AFP Hosts Symposium on Essentials for Doing Bu...   \n",
       "328183    4357  AlertEnterprise Wins ASIS Accolades 2009 Secur...   \n",
       "328184    4357  Andrews International Introduces New Methodolo...   \n",
       "328185    4357  Innovation Strong Despite Recession: Human Res...   \n",
       "328186    4357  VideoIQ and Milestone Systems Partner to Deliv...   \n",
       "328187    4357  Phoenix Technologies to Showcase Cutting Edge ...   \n",
       "328188    4357  AnyDATA's APT-210 Tracking Device Measures Att...   \n",
       "328189    4357  Samplify Systems Announces Distribution Agreem...   \n",
       "328190    4357  Steelbox Demonstrates Open Video Framework wit...   \n",
       "328191    4357  Small Businesses Rely on Sage to Help Them Rid...   \n",
       "328192    4357  TimeSight Systems™ Announces Next-Generation P...   \n",
       "328193    4357  Diebold Makes Its Leading Monitoring Solutions...   \n",
       "328194    4357  GVI Security Solutions to Introduce AutoIP™ VM...   \n",
       "\n",
       "                                                    words    URL  word_count  \\\n",
       "0       [handle, lets, try, and, catch, up, live, next...  False           9   \n",
       "1       [going, to, watch, greys, on, the, big, screen...  False          10   \n",
       "2       [handle, my, pleasure, patrickhope, you, are, ...  False           7   \n",
       "3       [handle, hi, there, been, traveling, a, lot, a...  False          25   \n",
       "4       [rt, handle, looking, to, drink, clean, go, gr...  False          18   \n",
       "5       [rt, handle, ft, hood, officials, confirm, the...  False          17   \n",
       "6       [rt, handle, mickey, mouse, is, getting, a, ma...   True          10   \n",
       "7         [handle, how, did, u, get, the, invite, justin]  False           8   \n",
       "8       [handle, i, think, i, am, still, a, good, frie...  False          12   \n",
       "9       [handle, i, remember, i, am, fine, how, are, u...  False          11   \n",
       "10          [handle, thats, great, good, for, the, coach]  False           7   \n",
       "11      [handle, i, dont, want, to, picture, u, sittin...  False          14   \n",
       "12      [handle, d, thanks, for, the, rtsare, you, goi...  False          11   \n",
       "13              [handle, grrryou, must, be, going, crazy]  False           6   \n",
       "14      [handle, hi, there, just, catching, up, from, ...  False          13   \n",
       "15      [rt, handle, if, youre, looking, for, some, gr...   True          15   \n",
       "16      [rt, handle, retailers, who, aren, ’, t, engag...   True          17   \n",
       "17      [rt, handle, director, of, global, brand, mark...   True          17   \n",
       "18      [still, in, carwant, to, jump, out45, minutes,...  False           8   \n",
       "19      [rt, handle, only, surround, yourself, with, p...  False          15   \n",
       "20      [handle, wish, i, could, but, 247, w, stus, fa...  False          22   \n",
       "21      [rt, handle, help, us, help, musicares, vote, ...   True          11   \n",
       "22                          [handle, yum, save, me, some]  False           5   \n",
       "23      [rt, handle, gratitude, is, the, sign, of, nob...  False          12   \n",
       "24        [handle, i, dont, think, i, know, what, it, is]  False           9   \n",
       "25      [rt, handle, handle, just, found, you, via, ha...  False          23   \n",
       "26      [rt, handle, rt, handle, travelling, for, the,...   True          18   \n",
       "27        [just, entering, ohio, special, hi, to, handle]  False           7   \n",
       "28      [handle, well, we, agree, on, one, food, thing...  False          19   \n",
       "29                                      [handle, only, 1]  False           3   \n",
       "...                                                   ...    ...         ...   \n",
       "328165                                           [handle]  False           1   \n",
       "328166  [handle, please, add, me, to, the, awsms09, af...  False           9   \n",
       "328167  [handle, great, party, last, nightmet, some, t...  False           8   \n",
       "328168  [alta, phoenix, lofts, 1, phoenix, congrats, t...   True           9   \n",
       "328169           [you, manage, things, you, lead, people]  False           6   \n",
       "328170  [not, to, know, is, bad, not, to, wish, to, kn...  False          12   \n",
       "328171  [that, there, should, one, man, die, ignorant,...  False          17   \n",
       "328172                  [will, is, character, in, action]  False           5   \n",
       "328173  [what, the, mind, dwells, upon, the, body, act...  False           9   \n",
       "328174  [success, as, i, see, it, is, a, result, not, ...  False          11   \n",
       "328175  [all, generalizations, are, false, including, ...  False           7   \n",
       "328176  [it, is, the, province, of, knowledge, to, spe...  False          17   \n",
       "328177  [a, leader, once, convinced, that, a, particul...  False          21   \n",
       "328178  [you, can, not, make, excuses, and, money, at,...  False          11   \n",
       "328179  [henry, brothers, electronics, inc, to, partic...   True          13   \n",
       "328180  [techinsights, esc, uk, event, showcases, lead...   True          15   \n",
       "328181  [demofall, 09, announces, lineup, of, emerging...   True          17   \n",
       "328182  [afp, hosts, symposium, on, essentials, for, d...   True          11   \n",
       "328183  [alertenterprise, wins, asis, accolades, 2009,...   True          10   \n",
       "328184  [andrews, international, introduces, new, meth...   True          13   \n",
       "328185  [innovation, strong, despite, recession, human...   True          14   \n",
       "328186  [videoiq, and, milestone, systems, partner, to...   True          12   \n",
       "328187  [phoenix, technologies, to, showcase, cutting,...   True          14   \n",
       "328188  [anydatas, apt210, tracking, device, measures,...   True          11   \n",
       "328189  [samplify, systems, announces, distribution, a...   True          15   \n",
       "328190  [steelbox, demonstrates, open, video, framewor...   True          13   \n",
       "328191  [small, businesses, rely, on, sage, to, help, ...   True          13   \n",
       "328192  [timesight, systems™, announces, nextgeneratio...   True          12   \n",
       "328193  [diebold, makes, its, leading, monitoring, sol...   True          10   \n",
       "328194  [gvi, security, solutions, to, introduce, auto...   True          15   \n",
       "\n",
       "        sentence_length  text_length  sentiment  punctuation_per_tweet  \\\n",
       "0                    35           46     0.0000               0.065217   \n",
       "1                    49           66     0.0000               0.045455   \n",
       "2                    37           49     0.7263               0.061224   \n",
       "3                   100          132     0.4997               0.030303   \n",
       "4                    86          109     0.4019               0.036697   \n",
       "5                    86          105    -0.3400               0.028571   \n",
       "6                    43           76     0.0000               0.052632   \n",
       "7                    31           40     0.1531               0.050000   \n",
       "8                    40           55     0.8478               0.054545   \n",
       "9                    37           54     0.3510               0.092593   \n",
       "10                   31           46     0.8469               0.086957   \n",
       "11                   53           77     0.1996               0.051948   \n",
       "12                   46           63     0.4404               0.063492   \n",
       "13                   29           40    -0.4003               0.075000   \n",
       "14                   50           68     0.0000               0.044118   \n",
       "15                   63          105     0.6588               0.066667   \n",
       "16                   82          117     0.0516               0.034188   \n",
       "17                   86          135     0.5423               0.081481   \n",
       "18                   35           53     0.0000               0.037736   \n",
       "19                   81          101     0.0000               0.049505   \n",
       "20                   77          107    -0.3400               0.065421   \n",
       "21                   51           86     0.8172               0.058140   \n",
       "22                   19           30     0.6562               0.066667   \n",
       "23                   57           74     0.7430               0.067568   \n",
       "24                   29           40     0.0000               0.075000   \n",
       "25                   91          121     0.0000               0.041322   \n",
       "26                   76          124     0.4574               0.048387   \n",
       "27                   33           44     0.5080               0.068182   \n",
       "28                   81          106     0.8777               0.056604   \n",
       "29                   11           19     0.0000               0.105263   \n",
       "...                 ...          ...        ...                    ...   \n",
       "328165                6            7     0.0000               0.142857   \n",
       "328166               45           56     0.6369               0.053571   \n",
       "328167               46           57     0.8779               0.035088   \n",
       "328168               45           79     0.6776               0.063291   \n",
       "328169               28           35     0.0000               0.057143   \n",
       "328170               36           49    -0.8342               0.040816   \n",
       "328171               75           93    -0.8860               0.021505   \n",
       "328172               23           28     0.0000               0.035714   \n",
       "328173               36           46    -0.0258               0.043478   \n",
       "328174               32           45     0.5719               0.044444   \n",
       "328175               42           50     0.0000               0.040000   \n",
       "328176               68           85     0.7096               0.011765   \n",
       "328177               98          125     0.2960               0.016000   \n",
       "328178               41           52     0.0000               0.019231   \n",
       "328179               80          118     0.0000               0.050847   \n",
       "328180               99          135     0.0000               0.037037   \n",
       "328181               95          134     0.4404               0.029851   \n",
       "328182               61           92     0.0000               0.043478   \n",
       "328183               69          101     0.9451               0.049505   \n",
       "328184               99          135     0.6369               0.029630   \n",
       "328185               97          135     0.8192               0.029630   \n",
       "328186               89          122     0.4588               0.040984   \n",
       "328187               93          134    -0.1280               0.044776   \n",
       "328188               73          108     0.0000               0.055556   \n",
       "328189               97          134     0.7003               0.029851   \n",
       "328190               99          132     0.1779               0.030303   \n",
       "328191               63           96    -0.0258               0.041667   \n",
       "328192               93          129     0.4588               0.038760   \n",
       "328193               68           99     0.1779               0.040404   \n",
       "328194               91          128     0.4767               0.031250   \n",
       "\n",
       "        unique_ratio  avg_word_length    mention  Retweet  \\\n",
       "0           1.000000         3.888889  {@handle}    False   \n",
       "1           1.000000         4.900000         {}    False   \n",
       "2           1.000000         5.285714  {@handle}    False   \n",
       "3           0.960000         4.000000  {@handle}    False   \n",
       "4           0.888889         4.777778  {@handle}     True   \n",
       "5           1.000000         5.058824  {@handle}     True   \n",
       "6           0.900000         4.300000  {@handle}     True   \n",
       "7           1.000000         3.875000  {@handle}    False   \n",
       "8           0.916667         3.333333  {@handle}    False   \n",
       "9           0.909091         3.363636  {@handle}    False   \n",
       "10          1.000000         4.428571  {@handle}    False   \n",
       "11          0.928571         3.785714  {@handle}    False   \n",
       "12          1.000000         4.181818  {@handle}     True   \n",
       "13          1.000000         4.833333  {@handle}    False   \n",
       "14          1.000000         3.846154  {@handle}    False   \n",
       "15          1.000000         4.200000  {@handle}     True   \n",
       "16          1.000000         4.823529  {@handle}     True   \n",
       "17          1.000000         5.058824  {@handle}     True   \n",
       "18          1.000000         4.375000         {}    False   \n",
       "19          1.000000         5.400000  {@handle}     True   \n",
       "20          1.000000         3.500000  {@handle}    False   \n",
       "21          0.909091         4.636364  {@handle}     True   \n",
       "22          1.000000         3.800000  {@handle}    False   \n",
       "23          0.916667         4.750000  {@handle}     True   \n",
       "24          0.888889         3.222222  {@handle}    False   \n",
       "25          0.869565         3.956522  {@handle}     True   \n",
       "26          0.888889         4.222222  {@handle}     True   \n",
       "27          1.000000         4.714286  {@handle}    False   \n",
       "28          1.000000         4.263158  {@handle}    False   \n",
       "29          1.000000         3.666667  {@handle}    False   \n",
       "...              ...              ...        ...      ...   \n",
       "328165      1.000000         6.000000  {@handle}    False   \n",
       "328166      1.000000         5.000000  {@handle}     True   \n",
       "328167      1.000000         5.750000  {@handle}     True   \n",
       "328168      0.888889         5.000000         {}    False   \n",
       "328169      0.833333         4.666667         {}    False   \n",
       "328170      0.583333         3.000000         {}    False   \n",
       "328171      1.000000         4.411765         {}    False   \n",
       "328172      1.000000         4.600000         {}    False   \n",
       "328173      0.777778         4.000000         {}    False   \n",
       "328174      0.909091         2.909091         {}    False   \n",
       "328175      1.000000         6.000000         {}    False   \n",
       "328176      0.705882         4.000000         {}    False   \n",
       "328177      0.904762         4.666667         {}     True   \n",
       "328178      1.000000         3.727273         {}    False   \n",
       "328179      1.000000         6.153846         {}     True   \n",
       "328180      1.000000         6.600000         {}    False   \n",
       "328181      0.941176         5.588235         {}    False   \n",
       "328182      1.000000         5.545455         {}    False   \n",
       "328183      1.000000         6.900000         {}     True   \n",
       "328184      1.000000         7.615385         {}    False   \n",
       "328185      1.000000         6.928571         {}    False   \n",
       "328186      1.000000         7.416667         {}     True   \n",
       "328187      0.928571         6.642857         {}    False   \n",
       "328188      1.000000         6.636364         {}    False   \n",
       "328189      1.000000         6.466667         {}    False   \n",
       "328190      1.000000         7.615385         {}    False   \n",
       "328191      1.000000         4.846154         {}    False   \n",
       "328192      1.000000         7.750000         {}    False   \n",
       "328193      1.000000         6.800000         {}    False   \n",
       "328194      1.000000         6.066667         {}    False   \n",
       "\n",
       "                     Hashtag emojis  profanity location  \\\n",
       "0                         {}             False     None   \n",
       "1                         {}             False     None   \n",
       "2                         {}             False     None   \n",
       "3                         {}             False     None   \n",
       "4                         {}             False     None   \n",
       "5                         {}             False     None   \n",
       "6                         {}             False     None   \n",
       "7                         {}             False     None   \n",
       "8                         {}             False     None   \n",
       "9                         {}             False     None   \n",
       "10                        {}             False     None   \n",
       "11                        {}             False     None   \n",
       "12                        {}             False     None   \n",
       "13                        {}             False     None   \n",
       "14                        {}             False     None   \n",
       "15                        {}             False     None   \n",
       "16                        {}             False     None   \n",
       "17        {#jobs, #twitjobs}             False     None   \n",
       "18                        {}             False     None   \n",
       "19            {#inspiration}             False     None   \n",
       "20                        {}    Sad      False     None   \n",
       "21                        {}             False     None   \n",
       "22                        {}             False     None   \n",
       "23      {#gratitude, #quote}             False     None   \n",
       "24                        {}             False     None   \n",
       "25                        {}             False     None   \n",
       "26                        {}             False     None   \n",
       "27                        {}             False     ohio   \n",
       "28           {#tweetsgiving}             False     None   \n",
       "29                        {}             False     None   \n",
       "...                      ...    ...        ...      ...   \n",
       "328165                    {}             False     None   \n",
       "328166            {#awsms09}             False     None   \n",
       "328167                    {}             False     None   \n",
       "328168                  {#1}             False     None   \n",
       "328169                    {}             False     None   \n",
       "328170                    {}             False     None   \n",
       "328171                    {}             False     None   \n",
       "328172                    {}             False     None   \n",
       "328173                    {}             False     None   \n",
       "328174                    {}             False     None   \n",
       "328175                    {}             False     None   \n",
       "328176                    {}             False     None   \n",
       "328177                    {}             False     None   \n",
       "328178                    {}             False     None   \n",
       "328179          {#tradeshow}             False     None   \n",
       "328180          {#tradeshow}             False       UK   \n",
       "328181          {#tradeshow}             False     None   \n",
       "328182          {#tradeshow}             False    China   \n",
       "328183          {#tradeshow}             False     None   \n",
       "328184          {#tradeshow}             False     None   \n",
       "328185          {#tradeshow}             False     None   \n",
       "328186          {#tradeshow}             False     None   \n",
       "328187          {#tradeshow}             False     None   \n",
       "328188          {#tradeshow}             False     None   \n",
       "328189          {#tradeshow}             False     None   \n",
       "328190          {#tradeshow}             False     None   \n",
       "328191          {#tradeshow}             False     None   \n",
       "328192          {#tradeshow}             False     None   \n",
       "328193          {#tradeshow}             False     None   \n",
       "328194          {#tradeshow}             False     None   \n",
       "\n",
       "                                                transform  \n",
       "0                     handle let try catch live next week  \n",
       "1            go watch grey big screen thursday indulgence  \n",
       "2                        handle pleasure patrickhope well  \n",
       "3       handle hi travel lot lot come next month recov...  \n",
       "4       rt handle look drink clean go green purchase c...  \n",
       "5       rt handle ft hood official confirm 2 soldier i...  \n",
       "6                  rt handle mickey mouse get make handle  \n",
       "7                              handle u get invite justin  \n",
       "8                      handle think still good friend lol  \n",
       "9                              handle remember fine u new  \n",
       "10                                handle great good coach  \n",
       "11          handle dont want picture u sit lol understand  \n",
       "12                    handle thank rtsare go womma summit  \n",
       "13                           handle grrryou must go crazy  \n",
       "14                         handle hi catch trip news dale  \n",
       "15      rt handle youre look great list follow check mine  \n",
       "16      rt handle retailer ’ engage customer social me...  \n",
       "17      rt handle director global brand marketing hote...  \n",
       "18                    still carwant jump out45 minute eta  \n",
       "19      rt handle surround people lift high oprah winf...  \n",
       "20      handle wish could 247 w stus family drive home...  \n",
       "21      rt handle help us help musicare vote charity f...  \n",
       "22                                        handle yum save  \n",
       "23      rt handle gratitude sign noble soul aesop quot...  \n",
       "24                                 handle dont think know  \n",
       "25      rt handle handle find via handle sheesh handle...  \n",
       "26      rt handle rt handle travel holiday send us pic...  \n",
       "27                           enter ohio special hi handle  \n",
       "28      handle well agree one food thing friend pumpki...  \n",
       "29                                               handle 1  \n",
       "...                                                   ...  \n",
       "328165                                             handle  \n",
       "328166         handle please add awsms09 afterparty thank  \n",
       "328167   handle great party last nightmet talented people  \n",
       "328168        alta phoenix loft 1 phoenix congrat involve  \n",
       "328169                           manage thing lead people  \n",
       "328170                     not know bad not wish know bad  \n",
       "328171  one man die ignorant capacity knowledge call t...  \n",
       "328172                                   character action  \n",
       "328173                      mind dwell upon body act upon  \n",
       "328174                        success see result not goal  \n",
       "328175                   generalization false include one  \n",
       "328176   province knowledge speak privilege wisdom listen  \n",
       "328177  leader convinced particular course action righ...  \n",
       "328178                         not make excuse money time  \n",
       "328179  henry brother electronic inc participate asis ...  \n",
       "328180  techinsight esc uk event showcase lead company...  \n",
       "328181  demofall 09 announce lineup emerge technology ...  \n",
       "328182  afp host symposium essential business china tr...  \n",
       "328183  alertenterprise win asis accolade 2009 securit...  \n",
       "328184  andrew international introduce new methodology...  \n",
       "328185  innovation strong despite recession human reso...  \n",
       "328186  videoiq milestone system partner deliver integ...  \n",
       "328187  phoenix technology showcase cut edge technolog...  \n",
       "328188  anydatas apt210 tracking device measure attemp...  \n",
       "328189  samplify system announce distribution agreemen...  \n",
       "328190  steelbox demonstrate open video framework sri ...  \n",
       "328191  small business rely sage help ride recession t...  \n",
       "328192  timesight system ™ announce nextgeneration pla...  \n",
       "328193  diebold make lead monitoring solution availabl...  \n",
       "328194  gvi security solution introduce autoip ™ vms i...  \n",
       "\n",
       "[328195 rows x 18 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processor = PreProcessor()\n",
    "clean_train = processor.transform_text1(train_data)\n",
    "clean_train.head(60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'clean_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-6c1cfc1e5654>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mqgrid\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mqgrid_widget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mqgrid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow_grid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclean_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshow_toolbar\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mqgrid_widget\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'clean_train' is not defined"
     ]
    }
   ],
   "source": [
    "import qgrid\n",
    "qgrid_widget = qgrid.show_grid(clean_train, show_toolbar=True)\n",
    "qgrid_widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_pickle(clean_train, os.path.join('train_data.p'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9293\n"
     ]
    }
   ],
   "source": [
    "df = train_data['Author'].unique()\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Author</th>\n",
       "      <th>word_count</th>\n",
       "      <th>text_length</th>\n",
       "      <th>punctuation_per_tweet</th>\n",
       "      <th>unique_ratio</th>\n",
       "      <th>avg_word_length</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>271828</th>\n",
       "      <td>2779</td>\n",
       "      <td>5</td>\n",
       "      <td>34</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>5.800000</td>\n",
       "      <td>0.4404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>283903</th>\n",
       "      <td>6970</td>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>4.333333</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66222</th>\n",
       "      <td>2016</td>\n",
       "      <td>16</td>\n",
       "      <td>108</td>\n",
       "      <td>0.027778</td>\n",
       "      <td>0.9375</td>\n",
       "      <td>4.562500</td>\n",
       "      <td>0.4019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82958</th>\n",
       "      <td>4535</td>\n",
       "      <td>14</td>\n",
       "      <td>68</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>3.642857</td>\n",
       "      <td>0.4019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105262</th>\n",
       "      <td>1614</td>\n",
       "      <td>6</td>\n",
       "      <td>37</td>\n",
       "      <td>0.027027</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>5.166667</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Author  word_count  text_length  punctuation_per_tweet  unique_ratio  \\\n",
       "271828    2779           5           34               0.029412        1.0000   \n",
       "283903    6970           3           16               0.062500        1.0000   \n",
       "66222     2016          16          108               0.027778        0.9375   \n",
       "82958     4535          14           68               0.058824        1.0000   \n",
       "105262    1614           6           37               0.027027        1.0000   \n",
       "\n",
       "        avg_word_length  sentiment  \n",
       "271828         5.800000     0.4404  \n",
       "283903         4.333333     0.0000  \n",
       "66222          4.562500     0.4019  \n",
       "82958          3.642857     0.4019  \n",
       "105262         5.166667     0.0000  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_columns = ['Author', 'word_count', 'text_length', 'punctuation_per_tweet', 'unique_ratio', 'avg_word_length', 'sentiment']\n",
    "df_features = train_data[feature_columns]\n",
    "df_train=df_features.sample(frac=0.8,random_state=1)\n",
    "df_dev=df_features.drop(df_train.index)\n",
    "\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# continual numeric features\n",
    "feature_word_count = tf.feature_column.numeric_column(\"word_count\")\n",
    "feature_text_length = tf.feature_column.numeric_column(\"text_length\")\n",
    "feature_punctuation_per_char = tf.feature_column.numeric_column(\"punctuation_per_tweet\")\n",
    "feature_unique_ratio = tf.feature_column.numeric_column(\"unique_ratio\")\n",
    "feature_avg_word_length = tf.feature_column.numeric_column(\"avg_word_length\")\n",
    "feature_sentiment = tf.feature_column.numeric_column(\"sentiment\")\n",
    "##feature_sentiment = tf.feature_column.'URL'\n",
    "\n",
    "\n",
    "# if we just used the single top word we could do it this way (single-hot)\n",
    "# feature_top_words = tf.feature_column.categorical_column_with_vocabulary_list(\n",
    "#    \"top_words\", vocabulary_list=authors_top_words)\n",
    "\n",
    "# feature_top_words = tf.feature_column.indicator_column(tf.feature_column.categorical_column_with_vocabulary_list(\n",
    "#     \"top_words_test\", vocabulary_list=authors_top_words))\n",
    "\n",
    "base_columns = [\n",
    "    feature_word_count, feature_text_length, feature_punctuation_per_char, feature_unique_ratio, feature_avg_word_length, feature_sentiment\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_model_dir': '/var/folders/3d/z13r7bqd6sv0d8qb3thz1dq80000gp/T/tmpy2zkutdz', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x1a524ded68>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    }
   ],
   "source": [
    "import tempfile\n",
    "\n",
    "model_dir = tempfile.mkdtemp() # base temp directory for running models\n",
    "\n",
    "# our Y value labels, i.e. the thing we are classifying\n",
    "labels_train = df_train['Author'].astype(str)\n",
    "\n",
    "# let's make a training function we can use with our estimators\n",
    "train_fn = tf.estimator.inputs.pandas_input_fn(\n",
    "    x=df_train,\n",
    "    y=labels_train,\n",
    "    batch_size=100,\n",
    "    num_epochs=None, # unlimited\n",
    "    shuffle=True, # shuffle the training data around\n",
    "    num_threads=5)\n",
    "\n",
    "# let's try a simple linear classifier\n",
    "linear_model = tf.estimator.LinearClassifier(\n",
    "    model_dir=model_dir, \n",
    "    feature_columns=base_columns,\n",
    "    n_classes=9293,\n",
    "    label_vocabulary= authors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From //anaconda3/lib/python3.7/site-packages/tensorflow/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
      "WARNING:tensorflow:From //anaconda3/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/inputs/queues/feeding_queue_runner.py:62: QueueRunner.__init__ (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "WARNING:tensorflow:From //anaconda3/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/inputs/queues/feeding_functions.py:500: add_queue_runner (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:From //anaconda3/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/canned/linear.py:308: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "WARNING:tensorflow:From //anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/array_ops.py:1354: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "WARNING:tensorflow:From //anaconda3/lib/python3.7/site-packages/tensorflow/python/training/monitored_session.py:875: start_queue_runners (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into /var/folders/3d/z13r7bqd6sv0d8qb3thz1dq80000gp/T/tmpy2zkutdz/model.ckpt.\n",
      "INFO:tensorflow:loss = 913.70166, step = 1\n",
      "INFO:tensorflow:global_step/sec: 69.6862\n",
      "INFO:tensorflow:loss = 4011.6992, step = 101 (1.436 sec)\n",
      "INFO:tensorflow:global_step/sec: 80.6714\n",
      "INFO:tensorflow:loss = 3705.0464, step = 201 (1.239 sec)\n",
      "INFO:tensorflow:global_step/sec: 90.3001\n",
      "INFO:tensorflow:loss = 3642.881, step = 301 (1.107 sec)\n",
      "INFO:tensorflow:global_step/sec: 89.8348\n",
      "INFO:tensorflow:loss = 3206.4941, step = 401 (1.113 sec)\n",
      "INFO:tensorflow:global_step/sec: 78.3153\n",
      "INFO:tensorflow:loss = 2888.2698, step = 501 (1.277 sec)\n",
      "INFO:tensorflow:global_step/sec: 88.9015\n",
      "INFO:tensorflow:loss = 2691.6484, step = 601 (1.124 sec)\n",
      "INFO:tensorflow:global_step/sec: 82.3818\n",
      "INFO:tensorflow:loss = 2469.244, step = 701 (1.214 sec)\n",
      "INFO:tensorflow:global_step/sec: 88.3011\n",
      "INFO:tensorflow:loss = 2498.0305, step = 801 (1.132 sec)\n",
      "INFO:tensorflow:global_step/sec: 89.741\n",
      "INFO:tensorflow:loss = 2802.1877, step = 901 (1.115 sec)\n",
      "INFO:tensorflow:global_step/sec: 83.2952\n",
      "INFO:tensorflow:loss = 2156.5212, step = 1001 (1.200 sec)\n",
      "INFO:tensorflow:global_step/sec: 86.7375\n",
      "INFO:tensorflow:loss = 2323.9976, step = 1101 (1.153 sec)\n",
      "INFO:tensorflow:global_step/sec: 88.5421\n",
      "INFO:tensorflow:loss = 1988.3643, step = 1201 (1.129 sec)\n",
      "INFO:tensorflow:global_step/sec: 82.607\n",
      "INFO:tensorflow:loss = 2014.3535, step = 1301 (1.211 sec)\n",
      "INFO:tensorflow:global_step/sec: 85.4856\n",
      "INFO:tensorflow:loss = 1883.9684, step = 1401 (1.170 sec)\n",
      "INFO:tensorflow:global_step/sec: 80.7598\n",
      "INFO:tensorflow:loss = 1757.8457, step = 1501 (1.238 sec)\n",
      "INFO:tensorflow:global_step/sec: 83.1986\n",
      "INFO:tensorflow:loss = 1656.7156, step = 1601 (1.202 sec)\n",
      "INFO:tensorflow:global_step/sec: 85.688\n",
      "INFO:tensorflow:loss = 1621.111, step = 1701 (1.167 sec)\n",
      "INFO:tensorflow:global_step/sec: 76.1585\n",
      "INFO:tensorflow:loss = 1644.1715, step = 1801 (1.313 sec)\n",
      "INFO:tensorflow:global_step/sec: 78.2664\n",
      "INFO:tensorflow:loss = 1672.8745, step = 1901 (1.277 sec)\n",
      "INFO:tensorflow:global_step/sec: 86.0633\n",
      "INFO:tensorflow:loss = 1500.9261, step = 2001 (1.162 sec)\n",
      "INFO:tensorflow:global_step/sec: 87.8264\n",
      "INFO:tensorflow:loss = 1651.3309, step = 2101 (1.139 sec)\n",
      "INFO:tensorflow:global_step/sec: 91.3578\n",
      "INFO:tensorflow:loss = 1381.3328, step = 2201 (1.095 sec)\n",
      "INFO:tensorflow:global_step/sec: 88.8122\n",
      "INFO:tensorflow:loss = 1397.6908, step = 2301 (1.125 sec)\n",
      "INFO:tensorflow:global_step/sec: 78.621\n",
      "INFO:tensorflow:loss = 1469.205, step = 2401 (1.272 sec)\n",
      "INFO:tensorflow:global_step/sec: 77.1387\n",
      "INFO:tensorflow:loss = 1408.1772, step = 2501 (1.296 sec)\n",
      "INFO:tensorflow:global_step/sec: 76.7909\n",
      "INFO:tensorflow:loss = 1253.2837, step = 2601 (1.302 sec)\n",
      "INFO:tensorflow:global_step/sec: 84.0996\n",
      "INFO:tensorflow:loss = 1120.9601, step = 2701 (1.189 sec)\n",
      "INFO:tensorflow:global_step/sec: 74.6654\n",
      "INFO:tensorflow:loss = 1226.0807, step = 2801 (1.340 sec)\n",
      "INFO:tensorflow:global_step/sec: 81.0376\n",
      "INFO:tensorflow:loss = 1244.0502, step = 2901 (1.234 sec)\n",
      "INFO:tensorflow:global_step/sec: 84.8407\n",
      "INFO:tensorflow:loss = 1198.8416, step = 3001 (1.178 sec)\n",
      "INFO:tensorflow:global_step/sec: 93.8519\n",
      "INFO:tensorflow:loss = 1171.9583, step = 3101 (1.066 sec)\n",
      "INFO:tensorflow:global_step/sec: 79.5246\n",
      "INFO:tensorflow:loss = 1225.7478, step = 3201 (1.257 sec)\n",
      "INFO:tensorflow:global_step/sec: 88.4066\n",
      "INFO:tensorflow:loss = 1073.7991, step = 3301 (1.131 sec)\n",
      "INFO:tensorflow:global_step/sec: 94.2312\n",
      "INFO:tensorflow:loss = 1078.7079, step = 3401 (1.061 sec)\n",
      "INFO:tensorflow:global_step/sec: 95.9123\n",
      "INFO:tensorflow:loss = 1178.8909, step = 3501 (1.043 sec)\n",
      "INFO:tensorflow:global_step/sec: 94.2196\n",
      "INFO:tensorflow:loss = 945.90936, step = 3601 (1.061 sec)\n",
      "INFO:tensorflow:global_step/sec: 96.4571\n",
      "INFO:tensorflow:loss = 1050.6528, step = 3701 (1.037 sec)\n",
      "INFO:tensorflow:global_step/sec: 88.2612\n",
      "INFO:tensorflow:loss = 1247.225, step = 3801 (1.133 sec)\n",
      "INFO:tensorflow:global_step/sec: 89.67\n",
      "INFO:tensorflow:loss = 1049.1787, step = 3901 (1.116 sec)\n",
      "INFO:tensorflow:global_step/sec: 91.9151\n",
      "INFO:tensorflow:loss = 987.3072, step = 4001 (1.087 sec)\n",
      "INFO:tensorflow:global_step/sec: 89.1683\n",
      "INFO:tensorflow:loss = 1003.19885, step = 4101 (1.122 sec)\n",
      "INFO:tensorflow:global_step/sec: 90.0452\n",
      "INFO:tensorflow:loss = 1057.1361, step = 4201 (1.111 sec)\n",
      "INFO:tensorflow:global_step/sec: 84.929\n",
      "INFO:tensorflow:loss = 920.34296, step = 4301 (1.177 sec)\n",
      "INFO:tensorflow:global_step/sec: 85.5639\n",
      "INFO:tensorflow:loss = 997.3824, step = 4401 (1.169 sec)\n",
      "INFO:tensorflow:global_step/sec: 91.5418\n",
      "INFO:tensorflow:loss = 981.37836, step = 4501 (1.092 sec)\n",
      "INFO:tensorflow:global_step/sec: 94.6684\n",
      "INFO:tensorflow:loss = 985.17926, step = 4601 (1.056 sec)\n",
      "INFO:tensorflow:global_step/sec: 88.1723\n",
      "INFO:tensorflow:loss = 976.2749, step = 4701 (1.134 sec)\n",
      "INFO:tensorflow:global_step/sec: 92.9962\n",
      "INFO:tensorflow:loss = 998.2128, step = 4801 (1.075 sec)\n",
      "INFO:tensorflow:global_step/sec: 90.8792\n",
      "INFO:tensorflow:loss = 933.44904, step = 4901 (1.101 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 5000 into /var/folders/3d/z13r7bqd6sv0d8qb3thz1dq80000gp/T/tmpy2zkutdz/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 1023.71265.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow_estimator.python.estimator.canned.linear.LinearClassifier at 0x1a524defd0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_steps = 5000\n",
    "\n",
    "# now let's train that model!\n",
    "linear_model.train(input_fn=train_fn, steps=train_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "authors = train_data.Author.unique().tolist()\n",
    "authors = list(map(str, authors))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "271828    2779\n",
      "283903    6970\n",
      "66222     2016\n",
      "82958     4535\n",
      "105262    1614\n",
      "128776    6362\n",
      "265964     946\n",
      "146866    9066\n",
      "60946     1200\n",
      "175159    8075\n",
      "245539     612\n",
      "131689    9916\n",
      "230051    4462\n",
      "268456    4253\n",
      "91792     5659\n",
      "202557    7232\n",
      "321222    9558\n",
      "254326    1613\n",
      "62053     6203\n",
      "210410    3666\n",
      "129081     274\n",
      "222739    5238\n",
      "278044    4598\n",
      "47349     7796\n",
      "192297    5293\n",
      "114101    9543\n",
      "295026    5682\n",
      "322966     966\n",
      "50602     7086\n",
      "160855    7442\n",
      "          ... \n",
      "162771    3118\n",
      "54790     7887\n",
      "211248    1034\n",
      "55646     5086\n",
      "186061    3356\n",
      "71384     9759\n",
      "170702    1896\n",
      "205685    9359\n",
      "196465    5517\n",
      "97189     4748\n",
      "277360    4988\n",
      "10698     6871\n",
      "5768      9556\n",
      "114463    5968\n",
      "216011    8498\n",
      "125686    9063\n",
      "115519    7663\n",
      "171420    7776\n",
      "124897    3672\n",
      "57207     3234\n",
      "59351      271\n",
      "70430     2785\n",
      "203047    9868\n",
      "220201    8192\n",
      "86341     8878\n",
      "37943     1395\n",
      "37130     4317\n",
      "253130    2370\n",
      "23474     4240\n",
      "220781    8616\n",
      "Name: Author, Length: 262556, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:enqueue_data was called with num_epochs and num_threads > 1. num_epochs is applied per thread, so this will produce more epochs than you probably intend. If you want to limit epochs, use one thread.\n",
      "WARNING:tensorflow:enqueue_data was called with shuffle=False and num_threads > 1. This will create multiple threads, all reading the array/dataframe in order. If you want examples read in order, use one thread; if you want multiple threads, enable shuffling.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-09-04T16:28:40Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "WARNING:tensorflow:From //anaconda3/lib/python3.7/site-packages/tensorflow/python/training/saver.py:1276: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n",
      "INFO:tensorflow:Restoring parameters from /var/folders/3d/z13r7bqd6sv0d8qb3thz1dq80000gp/T/tmpy2zkutdz/model.ckpt-5000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2019-09-04-16:29:15\n",
      "INFO:tensorflow:Saving dict for global step 5000: accuracy = 0.001279727, average_loss = 9.84751, global_step = 5000, loss = 984.73596\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 5000: /var/folders/3d/z13r7bqd6sv0d8qb3thz1dq80000gp/T/tmpy2zkutdz/model.ckpt-5000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.001279727"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_test_fn = tf.estimator.inputs.pandas_input_fn(\n",
    "    x=df_dev,\n",
    "    y=df_dev['Author'].astype(str),\n",
    "    batch_size=100,\n",
    "    num_epochs=1, # just one run\n",
    "    shuffle=False, # don't shuffle test here\n",
    "    num_threads=5)\n",
    "\n",
    "linear_model.evaluate(input_fn=dev_test_fn)[\"accuracy\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "features_train, features_test, labels_train, labels_test = train_test_split(clean_train['Tweet'], clean_train['Author'], test_size=0.1, random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4508445"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_train['Tweet'].apply(lambda x: len(x.split(' '))).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-71-889b46fb6b53>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mcnt_pro\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0mclean_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Author'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue_counts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0msns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbarplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcnt_pro\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcnt_pro\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Number of Occurrences'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfontsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Author'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfontsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/seaborn/categorical.py\u001b[0m in \u001b[0;36mbarplot\u001b[0;34m(x, y, hue, data, order, hue_order, estimator, ci, n_boot, units, orient, color, palette, saturation, errcolor, errwidth, capsize, dodge, ax, **kwargs)\u001b[0m\n\u001b[1;32m   3152\u001b[0m         \u001b[0max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgca\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3154\u001b[0;31m     \u001b[0mplotter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3155\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3156\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/seaborn/categorical.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(self, ax, bar_kws)\u001b[0m\n\u001b[1;32m   1659\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbar_kws\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1660\u001b[0m         \u001b[0;34m\"\"\"Make the plot.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1661\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw_bars\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbar_kws\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1662\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mannotate_axes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1663\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0morient\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"h\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/seaborn/categorical.py\u001b[0m in \u001b[0;36mdraw_bars\u001b[0;34m(self, ax, kws)\u001b[0m\n\u001b[1;32m   1634\u001b[0m                                \u001b[0merrcolors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1635\u001b[0m                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrwidth\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1636\u001b[0;31m                                self.capsize)\n\u001b[0m\u001b[1;32m   1637\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1638\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/seaborn/categorical.py\u001b[0m in \u001b[0;36mdraw_confints\u001b[0;34m(self, ax, at_group, confint, colors, errwidth, capsize, **kws)\u001b[0m\n\u001b[1;32m   1579\u001b[0m                                                 colors):\n\u001b[1;32m   1580\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0morient\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"v\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1581\u001b[0;31m                 \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mat\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mci_low\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mci_high\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcolor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkws\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1582\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mcapsize\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1583\u001b[0m                     ax.plot([at - capsize / 2, at + capsize / 2],\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/matplotlib/__init__.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(ax, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1808\u001b[0m                         \u001b[0;34m\"the Matplotlib list!)\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlabel_namer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1809\u001b[0m                         RuntimeWarning, stacklevel=2)\n\u001b[0;32m-> 1810\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1811\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1812\u001b[0m         inner.__doc__ = _add_data_doc(inner.__doc__,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(self, scalex, scaley, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1613\u001b[0m             \u001b[0mlines\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1614\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1615\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautoscale_view\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscalex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscalex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscaley\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscaley\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1616\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlines\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1617\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36mautoscale_view\u001b[0;34m(self, tight, scalex, scaley)\u001b[0m\n\u001b[1;32m   2426\u001b[0m             \u001b[0mstickies\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0martist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msticky_edges\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0martist\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_children\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2427\u001b[0m             \u001b[0mx_stickies\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msticky\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msticky\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstickies\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2428\u001b[0;31m             \u001b[0my_stickies\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msticky\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msticky\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstickies\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2429\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_xscale\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'log'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2430\u001b[0m                 \u001b[0mx_stickies\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mxs\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mxs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx_stickies\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mxs\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cnt_pro =clean_train['Author'].value_counts()\n",
    "plt.figure(figsize=(12,4))\n",
    "sns.barplot(cnt_pro.index, cnt_pro.values, alpha=0.8)\n",
    "plt.ylabel('Number of Occurrences', fontsize=12)\n",
    "plt.xlabel('Author', fontsize=12)\n",
    "plt.xticks(rotation=90)\n",
    "plt.show();\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_tweet(index):\n",
    "    example = clean_train[clean_train.index == index][['Tweet', 'Author']].values[0]\n",
    "    if len(example) > 0:\n",
    "        print(example[0])\n",
    "        print('Author:', example[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@handle Let's try and catch up live next week!\n",
      "Author: 8746\n"
     ]
    }
   ],
   "source": [
    "print_tweet(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(clean_train, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.doc2vec import Doc2Vec\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas(desc=\"progress-bar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.doc2vec import TaggedDocument\n",
    "def split(text):\n",
    "    return text.split()\n",
    "\n",
    "train_tagged = train.apply(lambda r: TaggedDocument(words=split(r['transform']), tags=[str(r.Author)]), axis=1)\n",
    "test_tagged = test.apply(lambda r: TaggedDocument(words=split(r['transform']), tags=[str(r.Author)]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TaggedDocument(words=['move', 'soon', 'go', 'need', 'place', 'stay', 'anyone', 'need', 'new', 'roomie', 'pay', 'rent', 'stress'], tags=['9064'])"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_tagged.values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "cores = multiprocessing.cpu_count()\n",
    "model_dbow = Doc2Vec(dm=0, vector_size=300, negative=5, hs=0, min_count=2, sample = 0, workers=cores)\n",
    "model_dbow.build_vocab([x for x in train_tagged.values])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 262556/262556 [00:00<00:00, 2508610.07it/s]\n",
      "100%|██████████| 262556/262556 [00:00<00:00, 2874901.60it/s]\n",
      "100%|██████████| 262556/262556 [00:00<00:00, 2860310.80it/s]\n",
      "100%|██████████| 262556/262556 [00:00<00:00, 3229896.53it/s]\n",
      "100%|██████████| 262556/262556 [00:00<00:00, 3100747.23it/s]\n",
      "100%|██████████| 262556/262556 [00:00<00:00, 3026256.70it/s]\n",
      "100%|██████████| 262556/262556 [00:00<00:00, 3058735.72it/s]\n",
      "100%|██████████| 262556/262556 [00:00<00:00, 3188994.95it/s]\n",
      "100%|██████████| 262556/262556 [00:00<00:00, 3277069.91it/s]\n",
      "100%|██████████| 262556/262556 [00:00<00:00, 3137917.75it/s]\n",
      "100%|██████████| 262556/262556 [00:00<00:00, 2996497.18it/s]\n",
      "100%|██████████| 262556/262556 [00:00<00:00, 2824792.43it/s]\n",
      "100%|██████████| 262556/262556 [00:00<00:00, 3233168.08it/s]\n",
      "100%|██████████| 262556/262556 [00:00<00:00, 3218117.13it/s]\n",
      "100%|██████████| 262556/262556 [00:00<00:00, 3055604.00it/s]\n",
      "100%|██████████| 262556/262556 [00:00<00:00, 2936412.07it/s]\n",
      "100%|██████████| 262556/262556 [00:00<00:00, 2890339.76it/s]\n",
      "100%|██████████| 262556/262556 [00:00<00:00, 2946665.67it/s]\n",
      "100%|██████████| 262556/262556 [00:00<00:00, 3223684.62it/s]\n",
      "100%|██████████| 262556/262556 [00:00<00:00, 3175422.45it/s]\n",
      "100%|██████████| 262556/262556 [00:00<00:00, 3117195.42it/s]\n",
      "100%|██████████| 262556/262556 [00:00<00:00, 3136871.96it/s]\n",
      "100%|██████████| 262556/262556 [00:00<00:00, 3272658.24it/s]\n",
      "100%|██████████| 262556/262556 [00:00<00:00, 3244235.98it/s]\n",
      "100%|██████████| 262556/262556 [00:00<00:00, 2950826.72it/s]\n",
      "100%|██████████| 262556/262556 [00:00<00:00, 2920889.71it/s]\n",
      "100%|██████████| 262556/262556 [00:00<00:00, 2967205.32it/s]\n",
      "100%|██████████| 262556/262556 [00:00<00:00, 2913980.04it/s]\n",
      "100%|██████████| 262556/262556 [00:00<00:00, 2833288.35it/s]\n",
      "100%|██████████| 262556/262556 [00:00<00:00, 2835747.05it/s]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import utils\n",
    "for epoch in range(30):\n",
    "    model_dbow.train(utils.shuffle([x for x in tqdm(train_tagged.values)]), total_examples=len(train_tagged.values), epochs=1)\n",
    "    model_dbow.alpha -= 0.002\n",
    "    model_dbow.min_alpha = model_dbow.alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vec_for_learning(model, tagged_docs):\n",
    "    sents = tagged_docs.values\n",
    "    targets, regressors = zip(*[(doc.tags[0], model.infer_vector(doc.words, steps=20)) for doc in sents])\n",
    "    return targets, regressors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/wangyizhou/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/wangyizhou/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "y_train, X_train = vec_for_learning(model_dbow, train_tagged)\n",
    "y_test, X_test = vec_for_learning(model_dbow, test_tagged)\n",
    "logreg = LogisticRegression(n_jobs=1, C=1e5)\n",
    "logreg.fit(X_train, y_train)\n",
    "y_pred = logreg.predict(X_test)\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "print('Testing accuracy %s' % accuracy_score(y_test, y_pred))\n",
    "print('Testing F1 score: {}'.format(f1_score(y_test, y_pred, average='weighted')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dmm = Doc2Vec(dm=1, dm_mean=1, vector_size=300, window=10, negative=5, min_count=1, workers=5, alpha=0.065, min_alpha=0.065)\n",
    "model_dmm.build_vocab([x for x in tqdm(train_tagged.values)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "for epoch in range(30):\n",
    "    model_dmm.train(utils.shuffle([x for x in tqdm(train_tagged.values)]), total_examples=len(train_tagged.values), epochs=1)\n",
    "    model_dmm.alpha -= 0.002\n",
    "    model_dmm.min_alpha = model_dmm.alpha\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "y_train, X_train = vec_for_learning(model_dmm, train_tagged)\n",
    "y_test, X_test = vec_for_learning(model_dmm, test_tagged)\n",
    "logreg.fit(X_train, y_train)\n",
    "y_pred = logreg.predict(X_test)\n",
    "print('Testing accuracy %s' % accuracy_score(y_test, y_pred))\n",
    "print('Testing F1 score: {}'.format(f1_score(y_test, y_pred, average='weighted')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dbow.delete_temporary_training_data(keep_doctags_vectors=True, keep_inference=True)\n",
    "model_dmm.delete_temporary_training_data(keep_doctags_vectors=True, keep_inference=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.test.test_doc2vec import ConcatenatedDoc2Vec\n",
    "new_model = ConcatenatedDoc2Vec([model_dbow, model_dmm])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vectors(model, tagged_docs):\n",
    "    sents = tagged_docs.values\n",
    "    targets, regressors = zip(*[(doc.tags[0], model.infer_vector(doc.words, steps=20)) for doc in sents])\n",
    "    return targets, regressors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train, X_train = get_vectors(new_model, train_tagged)\n",
    "y_test, X_test = get_vectors(new_model, test_tagged)\n",
    "logreg.fit(X_train, y_train)\n",
    "y_pred = logreg.predict(X_test)\n",
    "print('Testing accuracy %s' % accuracy_score(y_test, y_pred))\n",
    "print('Testing F1 score: {}'.format(f1_score(y_test, y_pred, average='weighted')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_pickle"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
